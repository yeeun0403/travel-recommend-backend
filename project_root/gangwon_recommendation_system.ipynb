{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b76b5130-236d-4f97-bee8-2c1e15b081bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in c:\\users\\tjdwl\\anaconda3\\lib\\site-packages (5.0.0)\n",
      "Requirement already satisfied: xgboost in c:\\users\\tjdwl\\anaconda3\\lib\\site-packages (3.0.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\tjdwl\\anaconda3\\lib\\site-packages (1.3.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\tjdwl\\anaconda3\\lib\\site-packages (1.5.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\tjdwl\\anaconda3\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\tjdwl\\anaconda3\\lib\\site-packages (1.2.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\tjdwl\\anaconda3\\lib\\site-packages (6.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\tjdwl\\anaconda3\\lib\\site-packages (4.65.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\tjdwl\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.53.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\tjdwl\\anaconda3\\lib\\site-packages (from sentence-transformers) (2.7.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\tjdwl\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.10.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\tjdwl\\anaconda3\\lib\\site-packages (from sentence-transformers) (0.33.2)\n",
      "Requirement already satisfied: Pillow in c:\\users\\tjdwl\\anaconda3\\lib\\site-packages (from sentence-transformers) (10.4.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\tjdwl\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.13.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\tjdwl\\anaconda3\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\tjdwl\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\tjdwl\\anaconda3\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: colorama in c:\\users\\tjdwl\\anaconda3\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: filelock in c:\\users\\tjdwl\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\tjdwl\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2023.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\tjdwl\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (23.1)\n",
      "Requirement already satisfied: requests in c:\\users\\tjdwl\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\tjdwl\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.17.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\tjdwl\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\tjdwl\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\tjdwl\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\tjdwl\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2023.10.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\tjdwl\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\tjdwl\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\tjdwl\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\tjdwl\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\tjdwl\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\tjdwl\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\tjdwl\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\tjdwl\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.4.26)\n",
      "Requirement already satisfied: tf-keras in c:\\users\\tjdwl\\anaconda3\\lib\\site-packages (2.19.0)\n",
      "Requirement already satisfied: tensorflow<2.20,>=2.19 in c:\\users\\tjdwl\\anaconda3\\lib\\site-packages (from tf-keras) (2.19.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\tjdwl\\anaconda3\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (2.2.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\tjdwl\\anaconda3\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\tjdwl\\anaconda3\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\tjdwl\\anaconda3\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\tjdwl\\anaconda3\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\tjdwl\\anaconda3\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\tjdwl\\anaconda3\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\tjdwl\\anaconda3\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\tjdwl\\anaconda3\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\tjdwl\\anaconda3\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\tjdwl\\anaconda3\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (80.4.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\tjdwl\\anaconda3\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\tjdwl\\anaconda3\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (3.0.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\tjdwl\\anaconda3\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (4.13.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\tjdwl\\anaconda3\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\tjdwl\\anaconda3\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (1.71.0)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in c:\\users\\tjdwl\\anaconda3\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (2.19.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\tjdwl\\anaconda3\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (3.9.1)\n",
      "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in c:\\users\\tjdwl\\anaconda3\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\tjdwl\\anaconda3\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (3.13.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in c:\\users\\tjdwl\\anaconda3\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (0.5.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\tjdwl\\anaconda3\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (0.31.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\tjdwl\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow<2.20,>=2.19->tf-keras) (0.41.2)\n",
      "Requirement already satisfied: rich in c:\\users\\tjdwl\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (13.3.5)\n",
      "Requirement already satisfied: namex in c:\\users\\tjdwl\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\tjdwl\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (0.14.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\tjdwl\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf-keras) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\tjdwl\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf-keras) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\tjdwl\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf-keras) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\tjdwl\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf-keras) (2025.4.26)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\tjdwl\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\tjdwl\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\tjdwl\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras) (2.2.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\tjdwl\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\users\\tjdwl\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\tjdwl\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\tjdwl\\anaconda3\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (0.1.0)\n",
      "Requirement already satisfied: sentence-transformers in c:\\users\\tjdwl\\anaconda3\\lib\\site-packages (5.0.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\tjdwl\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.53.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\tjdwl\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.65.0)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\tjdwl\\anaconda3\\lib\\site-packages (from sentence-transformers) (2.7.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\tjdwl\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.3.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\tjdwl\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.10.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\tjdwl\\anaconda3\\lib\\site-packages (from sentence-transformers) (0.33.2)\n",
      "Requirement already satisfied: Pillow in c:\\users\\tjdwl\\anaconda3\\lib\\site-packages (from sentence-transformers) (10.4.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\tjdwl\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.13.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\tjdwl\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\tjdwl\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2023.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\tjdwl\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\tjdwl\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0)\n",
      "Requirement already satisfied: requests in c:\\users\\tjdwl\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\tjdwl\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\tjdwl\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\tjdwl\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\tjdwl\\anaconda3\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\tjdwl\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\tjdwl\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2023.10.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\tjdwl\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\tjdwl\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\tjdwl\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\tjdwl\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\tjdwl\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\tjdwl\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\tjdwl\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\tjdwl\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\tjdwl\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\tjdwl\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.4.26)\n",
      "WARNING:tensorflow:From C:\\Users\\tjdwl\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## 라이브러리 설치 및 임포트\n",
    "## 필요한 라이버러리들이 없는 경우 아래 명령어로 설치\n",
    "!pip install sentence-transformers xgboost scikit-learn pandas numpy joblib pyyaml tqdm\n",
    "!pip install tf-keras\n",
    "!pip install sentence-transformers\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import yaml\n",
    "import joblib\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Tuple, Union\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "## 머신러닝 라이브러리\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import xgboost as xgb\n",
    "\n",
    "## 로깅 설정\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c82b16f9-6612-417b-bccb-62dbbbcbfda4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📁 프로젝트 디렉토리 구조가 준비되었습니다.\n",
      "   (폴더가 없다면 위의 주석을 해제하고 실행하세요)\n"
     ]
    }
   ],
   "source": [
    "# 폴더가 이미 만들어져 있다면 아래 코드는 실행하지 않아도 됩니다.\n",
    "# 필요시 주석을 해제하고 실행하세요.\n",
    "\n",
    "# def create_project_structure():\n",
    "#     \"\"\"프로젝트 디렉토리 구조를 생성합니다.\"\"\"\n",
    "#     \n",
    "#     directories = [\n",
    "#         'data/raw',\n",
    "#         'data/processed', \n",
    "#         'data/embeddings',\n",
    "#         'models/xgboost',\n",
    "#         'models/encoders',\n",
    "#         'src',\n",
    "#         'notebooks',\n",
    "#         'saved_models',\n",
    "#         'config',\n",
    "#         'logs'\n",
    "#     ]\n",
    "#     \n",
    "#     for directory in directories:\n",
    "#         Path(directory).mkdir(parents=True, exist_ok=True)\n",
    "#     \n",
    "#     print(\"✅ 프로젝트 디렉토리 구조 생성 완료\")\n",
    "\n",
    "# create_project_structure()  # 필요시 주석 해제\n",
    "\n",
    "print(\"📁 프로젝트 디렉토리 구조가 준비되었습니다.\")\n",
    "print(\"   (폴더가 없다면 위의 주석을 해제하고 실행하세요)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99ba1325-1757-4c23-95c2-0ae84b5f2664",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 설정 파일 생성\n",
    "\n",
    "config = {\n",
    "    'model' : {\n",
    "        'sbert_model' : 'snunlp/KR-SBERT-V40K-klueNLI-augSTS',\n",
    "        'embedding_dim' : 768,\n",
    "        'reduced_dim' : 128,\n",
    "        'dimensionality_reduction': 'PCA' ,\n",
    "        'xgboost_params' : {\n",
    "            'max_depth' : 6,\n",
    "            'learning_rate' : 0.1,\n",
    "            'n_estimators' : 100,\n",
    "            'random_state' : 42\n",
    "        }\n",
    "    },\n",
    "    'data' : {\n",
    "        'raw_file' : 'data/raw/gangwon_places_100.csv',\n",
    "        'processed_file' : 'data/processed/gangwon_places_100_processed.csv',\n",
    "        'embeddings_file' : 'data/embeddings/place_embeddings_pca128.npy'\n",
    "    },\n",
    "    'paths': {\n",
    "        'models' : 'models',\n",
    "        'encoders' : 'models/encoders',\n",
    "        'logs' : 'logs'\n",
    "    }\n",
    "}\n",
    "\n",
    "## config 폴더가 없으면 생성\n",
    "os.makedirs('config', exist_ok=True)\n",
    "\n",
    "## 설정 파일 저장\n",
    "with open('config/config.yaml', 'w', encoding='utf-8') as f: \n",
    "    yaml.dump(config, f, default_flow_style=False, allow_unicode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ac4009e-fadd-425f-9ac0-d59c3da4c566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 전처리 클래스 정의 완료\n"
     ]
    }
   ],
   "source": [
    "## 데이터 전처리 함수 정의\n",
    "\n",
    "class DataPreprocessor: \n",
    "    \"\"\"데이터 전처리 클래스\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.season_encoder = None\n",
    "        self.nature_encoder = MultiLabelBinarizer()\n",
    "        self.vibe_encoder = MultiLabelBinarizer()\n",
    "        self.target_encoder = MultiLabelBinarizer()\n",
    "\n",
    "    def parse_multi_label_string(self, text: str) -> List[str]:\n",
    "        \"\"\"쉼표로 구분된 문자열을 리스트로 변환\"\"\"\n",
    "        if pd.isna(text) or text == '':\n",
    "            return []\n",
    "\n",
    "        # 쉼표로 분리하고 공백 제거\n",
    "        items = [item.strip() for item in str(text).split(',')]\n",
    "        return [item for item in items if item] # 빈 문자열 제거\n",
    "\n",
    "    def preprocess_data(self, df: pd.DataFrame) -> pd.DataFrame: \n",
    "        \"\"\"데이터 전처리 메인 함수\"\"\"\n",
    "        # 복사본 생성\n",
    "        processed_df = df.copy()\n",
    "\n",
    "        # 필수 컬럼 확인\n",
    "        required_cols = ['name', 'season', 'nature', 'vibe', 'target', 'short_description']\n",
    "        missing_cols = [col for col in required_cols if col not in processed_df.columns]\n",
    "        if missing_cols:\n",
    "            raise ValueError(f\"필수 컬럼이 없습니다: {missing_cols}\")\n",
    "\n",
    "        # 결측치 처리\n",
    "        processed_df['short_description'] = processed_df['short_description'].fillna('')\n",
    "        processed_df['season'] = processed_df['season'].fillna('사계절')\n",
    "        processed_df['nature'] = processed_df['nature'].fillna('')\n",
    "        processed_df['vibe'] = processed_df['vibe'].fillna('')\n",
    "        processed_df['target'] = processed_df['target'].fillna('')\n",
    "\n",
    "        # 다중 라벨 파싱\n",
    "        processed_df['nature_list'] = processed_df['nature'].apply(self.parse_multi_label_string)\n",
    "        processed_df['vibe_list'] = processed_df['vibe'].apply(self.parse_multi_label_string)\n",
    "        processed_df['target_list'] = processed_df['target'].apply(self.parse_multi_label_string)\n",
    "\n",
    "        # 텍스트 정규화\n",
    "        processed_df['short_description'] = processed_df['short_description'].apply(\n",
    "        lambda x: re.sub(r'[^\\w\\s]', '', str(x)) if pd.notna(x) else ''\n",
    "        )\n",
    "        return processed_df\n",
    "\n",
    "    def fit_encoders(self, df: pd.DataFrame):\n",
    "        \"\"\"인코더들을 학습 데이터에 맞춤\"\"\"\n",
    "\n",
    "        # 계절은 단일 라벨이므로 LabelEncoder 대신 직접 처리\n",
    "        self.season_categories = sorted(df['season'].unique())\n",
    "\n",
    "        # 다중 라벨 인코더 학습\n",
    "        self.nature_encoder.fit(df['nature_list'])\n",
    "        self.vibe_encoder.fit(df['vibe_list'])\n",
    "        self.target_encoder.fit(df['target_list'])\n",
    "\n",
    "        print(f\"인코더 학습 완료\")\n",
    "        print(f\"   - 계절 카테고리: {self.season_categories}\")\n",
    "        print(f\"   - 자연환경 카테고리: {len(self.nature_encoder.classes_)}개\")\n",
    "        print(f\"   - 분위기 카테고리: {len(self.vibe_encoder.classes_)}개\")\n",
    "        print(f\"   - 대상 카테고리: {len(self.target_encoder.classes_)}개\")\n",
    "\n",
    "    def encode_labels(self, df: pd.DataFrame) -> Dict[str,np.ndarray]:\n",
    "        \"\"\"라벨들을 인코딩\"\"\"\n",
    "\n",
    "        # 계절 인코딩(원-핫 인코딩)\n",
    "        season_encoded = np.zeros((len(df), len(self.season_categories)))\n",
    "        for i, season in enumerate(df['season']):\n",
    "            if season in self.season_categories:\n",
    "                season_idx = self.season_categories.index(season)\n",
    "                season_encoded[i, season_idx] = 1\n",
    "\n",
    "        # 다중 라벨 인코등\n",
    "        nature_encoded = self.nature_encoder.transform(df['nature_list'])\n",
    "        vibe_encoded = self.vibe_encoder.transform(df['vibe_list'])\n",
    "        target_encoded = self.target_encoder.transform(df['target_list'])\n",
    "\n",
    "        return{\n",
    "            'season' : season_encoded,\n",
    "            'nature' : nature_encoded,\n",
    "            'vibe' : vibe_encoded,\n",
    "            'target' : target_encoded\n",
    "        }\n",
    "\n",
    "    def save_encoders(self, base_path: str):\n",
    "        \"\"\"인코더들을 저장\"\"\"\n",
    "        # 계절 카테고리 저장\n",
    "        joblib.dump(self.season_categories, f\"{base_path}/season_encoder.joblib\")\n",
    "\n",
    "        # 다중 라벨 인코더 저장\n",
    "        joblib.dump(self.nature_encoder, f\"{base_path}/nature_encoder.joblib\")\n",
    "        joblib.dump(self.vibe_encoder, f\"{base_path}/vibe_encoder.joblib\")\n",
    "        joblib.dump(self.target_encoder, f\"{base_path}/target_encoder.joblib\")\n",
    "\n",
    "        print(f\"인코더 저장 완료: {base_path}\")\n",
    "\n",
    "    def load_encoders(self, base_path: str):\n",
    "        \"\"\"인코더 로드\"\"\"\n",
    "\n",
    "        self.season_categories = joblib.load(f\"{base_path}/season_encoder.joblib\")\n",
    "        self.nature_encoder = joblib.load(f\"{base_path}/nature_encoder.joblib\")\n",
    "        self.vibe_encoder = joblib.load(f\"{base_path}/vibe_encoder.joblib\")\n",
    "        self.target_encoder = joblib.load(f\"{base_path}/target_encoder.joblib\")\n",
    "\n",
    "        print(f\"인코더 로드 완료: {base_path}\")\n",
    "\n",
    "print(f\"데이터 전처리 클래스 정의 완료\")\n",
    "         \n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e775a6e-6fdb-4c22-a1c7-024a7e48df42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "임베딩 생성 클래스 정의 완료\n"
     ]
    }
   ],
   "source": [
    "## 임베딩 생성 클래스 정의\n",
    "\n",
    "class EmbeddingGenerator:\n",
    "    \"\"\"SBERT 임베딩 생성 및 차원 축소 클래스\"\"\"\n",
    "\n",
    "    def __init__(self, model_name: str = 'snunlp/KR-SBERT-V40K-klueNLI-augSTS'):\n",
    "        self.model_name = model_name\n",
    "        self.model = None\n",
    "        self.dimension_reducer = None\n",
    "        self.reduced_dim = None\n",
    "\n",
    "    def load_model(self):\n",
    "        \"\"\"SBERT 모델 로드\"\"\"\n",
    "        print(f\"SBERT 모델 로드 중: {self.model_name}\")\n",
    "        self.model = SentenceTransformer(self.model_name)\n",
    "        print(\"SBERT 모델 로드 완료\")\n",
    "\n",
    "    def generate_embeddings(self, texts: List[str]) -> np.ndarray:\n",
    "        \"\"\"텍스트 리스트로부터 임베딩 생성\"\"\"\n",
    "\n",
    "        if self.model is None:\n",
    "            self.load_model()\n",
    "\n",
    "        print(f\"임베딩 생성 중... (총 {len(texts)}개 텍스트)\")\n",
    "  \n",
    "        # 배치 단위로 임베딩 생성(메모리 효율성)\n",
    "        batch_size = 32\n",
    "        embeddings = []\n",
    "\n",
    "        for i in tqdm(range(0, len(texts), batch_size)):\n",
    "            batch_texts = texts[i:i+batch_size]\n",
    "            batch_embeddings = self.model.encode(batch_texts, convert_to_numpy=True)\n",
    "            embeddings.append(batch_embeddings)\n",
    "\n",
    "        embeddings = np.vstack(embeddings)\n",
    "        print(f\"임베딩 생성 완료: {embeddings.shape}\")\n",
    "\n",
    "        return embeddings\n",
    "\n",
    "    def fit_dimension_reducer(self, embeddings: np.ndarray, method: str = 'PCA',\n",
    "                              target_dim: int = 128):\n",
    "        \"\"\"차원 축소 모델 학습\"\"\"\n",
    "\n",
    "        self.reduced_dim = target_dim\n",
    "\n",
    "        if method =='PCA':\n",
    "            self.dimension_reducer = PCA(n_components=target_dim, random_state=42)\n",
    "        elif method =='TruncatedSVD':\n",
    "            self.dimension_reducer = TruncatedSVD(n_components=target_dim, random_state=42)\n",
    "        else: \n",
    "            raise ValueError(f\"지원하지 않는 차원 축소 방법: {method}\")\n",
    "\n",
    "        print(f\"{method}를 사용하여 {embeddings.shape[1]}차원 -> {target_dim}차원으로 축소\")\n",
    "        self.dimension_reducer.fit(embeddings)\n",
    "\n",
    "        # 설명 분산 비율 출력(PCA의 경우)\n",
    "        if method =='PCA':\n",
    "            explained_variance_ratio = self.dimension_reducer.explained_variance_ratio_\n",
    "            cumulative_variance = np.cumsum(explained_variance_ratio)\n",
    "            print(f\"설명 분산 비율: {cumulative_variance[-1]:.4f}\")\n",
    "\n",
    "        print(f\"차원 축소 모델 학습 완료\")\n",
    "\n",
    "    def reduce_dimensions(self, embeddings: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"임베딩 차원 축소\"\"\"\n",
    "\n",
    "        if self.dimension_reducer is None:\n",
    "            raise ValueError(\"차원 축소 모델이 학습되지 않았습니다.\")\n",
    "\n",
    "        reduced_embeddings = self.dimension_reducer.transform(embeddings)\n",
    "        print(f\"차원 축소 완료: {embeddings.shape} -> {reduced_embeddings.shape}\")\n",
    "\n",
    "        return reduced_embeddings\n",
    "\n",
    "    def save_dimension_reducer(self, filepath: str):\n",
    "        \"\"\"차원 축소 모델 저장\"\"\"\n",
    "\n",
    "        model_data = {\n",
    "        'reducer': self.dimension_reducer,\n",
    "        'reduced_dim' : self.reduced_dim,\n",
    "        'model_name' : self.model_name\n",
    "        }\n",
    "        joblib.dump(model_data, filepath)\n",
    "        print(f\"차원 축소 모델 저장: {filepath}\")\n",
    "\n",
    "    def load_dimension_reducer(self, filepath: str):\n",
    "        \"\"\"차원 축소 모델 로드\"\"\"\n",
    "\n",
    "        model_data = joblib.load(filepath)\n",
    "        self.dimension_reducer = model_data['reducer']\n",
    "        self.reduced_dim = model_data['reduced_dim']\n",
    "        self.model_name = model_data['model_name']\n",
    "\n",
    "        print(f\"차원 축소 모델 로드: {filepath}\")\n",
    "\n",
    "print(\"임베딩 생성 클래스 정의 완료\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "232b2813-e02a-4589-9a3e-25c354b01830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost 학습 클래스 정의 완료\n"
     ]
    }
   ],
   "source": [
    "### XGBoost 학습 클래스 정의\n",
    "\n",
    "class XGBoostTrainer:\n",
    "    \"\"\"XGBoost 분류기 학습 클래스\"\"\"\n",
    "\n",
    "    def __init__(self, xgb_params: Dict):\n",
    "        self.xgb_params = xgb_params\n",
    "        self.models = {}\n",
    "        self.label_types = ['season', 'nature', 'vibe', 'target']\n",
    "\n",
    "    def train_models(self, feature: np.ndarray, labels: Dict[str, np.ndarray]):\n",
    "        \"\"\"모든 라벨 타입에 대해 분류기 학습\"\"\"\n",
    "\n",
    "        print(\"XGBoost 모델 학습 시작...\")\n",
    "\n",
    "        for label_type in self.label_types:\n",
    "            print(f\"\\n{label_type} 분류기 학습 중...\")\n",
    "\n",
    "            y = labels[label_type]\n",
    "\n",
    "            if label_type == 'season':\n",
    "                #단일 라벨: 원-핫에서 클래스 인덱스로 변환\n",
    "                y_single = np.argmax(y, axis=1)\n",
    "\n",
    "                model = xgb.XGBClassifier(**self.xgb_params)\n",
    "                model.fit(features, y_single)\n",
    "                           \n",
    "            else: \n",
    "                #다중 라벨: OneVsRestClassifier 사용\n",
    "                model = OneVsRestClassifier(\n",
    "                    xgb.XGBClassifier(**self.xgb_params)\n",
    "                )\n",
    "                model.fit(features, y)\n",
    "\n",
    "            self.models[label_type] = model\n",
    "            print(f\"모든 XGBoost 모델 학습 완료\")\n",
    "\n",
    "    def evaluate_models(self, features: np.ndarray, labels: Dict[str,np.ndarray]):\n",
    "        \"\"\"모델 성능 평가\"\"\"\n",
    "\n",
    "        print(\"\\n=== 모델 성능 평가===\")\n",
    "\n",
    "        for label_type in self.label_types:\n",
    "            print(f\"\\n[{label_type}] 성능 평가: \")\n",
    "\n",
    "\n",
    "            y_true = labels[label_type]\n",
    "            model = self.models[label_type]\n",
    "\n",
    "            if label_type == 'season':\n",
    "                # 단일 라벨 평가\n",
    "\n",
    "                y_true_single = np.argmax(y_true, axis=1)\n",
    "                y_pred = model.predict(features)\n",
    "\n",
    "                accuracy = accuracy_score(y_true_single, y_pred)\n",
    "                f1 = f1_score(y_true_single, y_pred, average='weighted')\n",
    "\n",
    "                print(f\"Accuracy: {accuracy:.4f}\")\n",
    "                print(f\"F1-Score: {f1:.4f}\")\n",
    "\n",
    "            else: \n",
    "                # 다중 라벨 평가\n",
    "                y_pred = model.predict(features)\n",
    "\n",
    "                accuracy = accuracy_score(y_true, y_pred)\n",
    "                f1_micro = f1_score(y_true, y_pred, average='micro')\n",
    "                f1_macro = f1_score(y_true, y_pred, average='macro')\n",
    "\n",
    "                print(f\"Accuracy: {accuracy:.4f}\")\n",
    "                print(f\"F1-Score (Micro): {f1_micro:.4f}\")\n",
    "                print(f\"F1-Score (Macro): {f1_macro:.4f}\")\n",
    "                \n",
    "    def save_models(self,base_path: str):\n",
    "        \"\"\"모델들 저장\"\"\"\n",
    "        for label_type in self.label_types:\n",
    "            model_path = f\"{base_path}/xgboost/{label_type}_model.joblib\"\n",
    "            joblib.dump(self.models[label_type], model_path)\n",
    "            print(f\"{label_type} 모델 저장: {model_path}\")\n",
    "\n",
    "    def load_models(self,base_path: str):\n",
    "        \"\"\"모델들 로드\"\"\"\n",
    "\n",
    "        for label_type in self.label_types:\n",
    "            model_path = f\"{base_path}/xgboost/{label_type}_model.joblib\"\n",
    "            self.models[label_type] = joblib.load(model_path)\n",
    "            print(f\"{label_type} 모델 로드: {model_path}\")\n",
    "\n",
    "print(\"XGBoost 학습 클래스 정의 완료\")\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5e54007-c9a4-41e9-90c0-cb6ee76bd9e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 수정된 추천 시스템 클래스 정의 완료\n"
     ]
    }
   ],
   "source": [
    "## 추천 시스템 클래스 정의\n",
    "\n",
    "# 새로운 셀에서 GangwonPlaceRecommender 클래스 재정의\n",
    "class GangwonPlaceRecommender:\n",
    "    \"\"\"강원도 관광지 추천 시스템 메인 클래스 (수정된 버전)\"\"\"\n",
    "    \n",
    "    def __init__(self, config_path: str = 'config/config.yaml'):\n",
    "        # 설정 로드\n",
    "        with open(config_path, 'r', encoding='utf-8') as f:\n",
    "            self.config = yaml.safe_load(f)\n",
    "        \n",
    "        # 컴포넌트 초기화\n",
    "        self.preprocessor = DataPreprocessor()\n",
    "        self.embedding_generator = EmbeddingGenerator(\n",
    "            self.config['model']['sbert_model']\n",
    "        )\n",
    "        self.xgb_trainer = XGBoostTrainer(\n",
    "            self.config['model']['xgboost_params']\n",
    "        )\n",
    "        \n",
    "        # 데이터 저장용\n",
    "        self.df = None\n",
    "        self.place_embeddings = None\n",
    "        self.place_names = None\n",
    "        \n",
    "        # 태그 매핑 (자유 문장 파싱용)\n",
    "        self.tag_mapping = {\n",
    "            'season': {\n",
    "                '봄': ['봄', '3월', '4월', '5월', '벚꽃', '꽃'],\n",
    "                '여름': ['여름', '6월', '7월', '8월', '바다', '해변', '시원', '물'],\n",
    "                '가을': ['가을', '9월', '10월', '11월', '단풍', '억새', '빨간'],\n",
    "                '겨울': ['겨울', '12월', '1월', '2월', '눈', '스키', '추운'],\n",
    "                '사계절': ['사계절', '연중', '언제나']\n",
    "            },\n",
    "            'nature': {\n",
    "                '산': ['산', '등산', '트레킹', '하이킹', '산책', '오르막'],\n",
    "                '바다': ['바다', '해변', '바닷가', '수영', '파도'],\n",
    "                '호수': ['호수', '연못', '물가', '저수지'],\n",
    "                '계곡': ['계곡', '시냇물', '개울', '물소리'],\n",
    "                '자연': ['자연', '숲', '나무', '풀', '식물'],\n",
    "                '도시': ['도시', '시내', '번화가', '상점']\n",
    "            },\n",
    "            'vibe': {\n",
    "                '감성': ['감성', '감성적', '로맨틱', '낭만', '예쁜'],\n",
    "                '활력': ['활력', '활기', '신나는', '즐거운', '재미'],\n",
    "                '휴식': ['휴식', '쉬는', '편안', '조용', '평온', '힐링'],\n",
    "                '산책': ['산책', '걷기', '거닐기', '천천히'],\n",
    "                '모험': ['모험', '스릴', '도전', '익스트림']\n",
    "            },\n",
    "            'target': {\n",
    "                '연인': ['연인', '커플', '남친', '여친', '애인'],\n",
    "                '가족': ['가족', '부모', '아이', '자녀', '아기'],\n",
    "                '친구': ['친구', '친구들', '동료', '같이'],\n",
    "                '혼자': ['혼자', '나만', '단독', '솔로']\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def parse_user_input(self, user_input: Dict) -> Dict:\n",
    "        \"\"\"사용자 입력을 파싱하여 표준화된 형태로 변환\"\"\"\n",
    "        \n",
    "        parsed = {\n",
    "            'season': None,\n",
    "            'nature': [],\n",
    "            'vibe': [],\n",
    "            'target': []\n",
    "        }\n",
    "        \n",
    "        # 자유 문장 입력 처리\n",
    "        if 'free_text' in user_input:\n",
    "            text = user_input['free_text'].lower()\n",
    "            \n",
    "            # 각 태그 카테고리별로 매칭\n",
    "            for category, tag_dict in self.tag_mapping.items():\n",
    "                for tag, keywords in tag_dict.items():\n",
    "                    if any(keyword in text for keyword in keywords):\n",
    "                        if category == 'season':\n",
    "                            parsed['season'] = tag\n",
    "                        else:\n",
    "                            if tag not in parsed[category]:\n",
    "                                parsed[category].append(tag)\n",
    "        \n",
    "        # 직접 태그 입력 처리\n",
    "        else:\n",
    "            if 'season' in user_input:\n",
    "                parsed['season'] = user_input['season']\n",
    "            \n",
    "            for category in ['nature', 'vibe', 'target']:\n",
    "                if category in user_input:\n",
    "                    if isinstance(user_input[category], list):\n",
    "                        parsed[category] = user_input[category]\n",
    "                    else:\n",
    "                        parsed[category] = [user_input[category]]\n",
    "        \n",
    "        return parsed\n",
    "    \n",
    "    def calculate_hybrid_score(self, user_input: Dict, \n",
    "                             similarity_weight: float = 0.6,\n",
    "                             tag_weight: float = 0.4) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "        \"\"\"유사도 점수와 태그 매칭 점수를 결합한 하이브리드 점수 계산\"\"\"\n",
    "        \n",
    "        # 사용자 입력 파싱\n",
    "        parsed_input = self.parse_user_input(user_input)\n",
    "        \n",
    "        # 1. 텍스트 유사도 점수 계산\n",
    "        if 'free_text' in user_input:\n",
    "            query_text = user_input['free_text']\n",
    "        else:\n",
    "            # 태그를 문장으로 변환\n",
    "            query_parts = []\n",
    "            if parsed_input['season']:\n",
    "                query_parts.append(f\"{parsed_input['season']}에\")\n",
    "            if parsed_input['target']:\n",
    "                query_parts.append(f\"{', '.join(parsed_input['target'])}와\")\n",
    "            if parsed_input['nature']:\n",
    "                query_parts.append(f\"{', '.join(parsed_input['nature'])}에서\")\n",
    "            if parsed_input['vibe']:\n",
    "                query_parts.append(f\"{', '.join(parsed_input['vibe'])} 여행\")\n",
    "            \n",
    "            query_text = ' '.join(query_parts)\n",
    "        \n",
    "        # 쿼리 임베딩 생성\n",
    "        if self.embedding_generator.model is None:\n",
    "            self.embedding_generator.load_model()\n",
    "        \n",
    "        query_embedding = self.embedding_generator.model.encode([query_text])\n",
    "        \n",
    "        # 코사인 유사도 계산 - [0] 인덱스로 1차원 배열로 변환\n",
    "        similarity_scores = cosine_similarity(\n",
    "            query_embedding, \n",
    "            self.place_embeddings\n",
    "        )[0]\n",
    "        \n",
    "        # 2. 태그 매칭 점수 계산\n",
    "        tag_scores = np.zeros(len(self.df))\n",
    "        \n",
    "        for idx, row in self.df.iterrows():\n",
    "            score = 0\n",
    "            total_weight = 0\n",
    "            \n",
    "            # 계절 매칭 (가중치 0.3)\n",
    "            if parsed_input['season'] and row['season'] == parsed_input['season']:\n",
    "                score += 0.3\n",
    "            total_weight += 0.3\n",
    "            \n",
    "            # 자연환경 매칭 (가중치 0.25)\n",
    "            if parsed_input['nature']:\n",
    "                nature_match = len(set(parsed_input['nature']) & set(row['nature_list']))\n",
    "                if nature_match > 0:\n",
    "                    score += 0.25 * (nature_match / len(parsed_input['nature']))\n",
    "            total_weight += 0.25\n",
    "            \n",
    "            # 분위기 매칭 (가중치 0.25)\n",
    "            if parsed_input['vibe']:\n",
    "                vibe_match = len(set(parsed_input['vibe']) & set(row['vibe_list']))\n",
    "                if vibe_match > 0:\n",
    "                    score += 0.25 * (vibe_match / len(parsed_input['vibe']))\n",
    "            total_weight += 0.25\n",
    "            \n",
    "            # 대상 매칭 (가중치 0.2)\n",
    "            if parsed_input['target']:\n",
    "                target_match = len(set(parsed_input['target']) & set(row['target_list']))\n",
    "                if target_match > 0:\n",
    "                    score += 0.2 * (target_match / len(parsed_input['target']))\n",
    "            total_weight += 0.2\n",
    "            \n",
    "            # 정규화\n",
    "            tag_scores[idx] = score / total_weight if total_weight > 0 else 0\n",
    "        \n",
    "        # 하이브리드 점수 계산\n",
    "        hybrid_scores = (similarity_weight * similarity_scores + \n",
    "                        tag_weight * tag_scores)\n",
    "        \n",
    "        return hybrid_scores, similarity_scores, tag_scores\n",
    "    \n",
    "    def recommend_places(self, user_input: Dict, top_k: int = 10) -> Dict:\n",
    "        \"\"\"관광지 추천 메인 함수\"\"\"\n",
    "        \n",
    "        # 하이브리드 점수 계산\n",
    "        hybrid_scores, similarity_scores, tag_scores = self.calculate_hybrid_score(user_input)\n",
    "        \n",
    "        # 상위 k개 추천지 선택\n",
    "        top_indices = np.argsort(hybrid_scores)[::-1][:top_k]\n",
    "        \n",
    "        # 추천 결과 구성\n",
    "        recommendations = []\n",
    "        for i, idx in enumerate(top_indices):\n",
    "            place_info = {\n",
    "                'name': self.df.iloc[idx]['name'],\n",
    "                'season': self.df.iloc[idx]['season'],\n",
    "                'nature': self.df.iloc[idx]['nature_list'],\n",
    "                'vibe': self.df.iloc[idx]['vibe_list'],\n",
    "                'target': self.df.iloc[idx]['target_list'],\n",
    "                'description': self.df.iloc[idx]['short_description'],\n",
    "                'hybrid_score': float(hybrid_scores[idx]),\n",
    "                'similarity_score': float(similarity_scores[idx]),\n",
    "                'tag_score': float(tag_scores[idx])\n",
    "            }\n",
    "            recommendations.append(place_info)\n",
    "        \n",
    "        # 파싱된 사용자 입력 정보 추가\n",
    "        parsed_input = self.parse_user_input(user_input)\n",
    "        \n",
    "        result = {\n",
    "            'user_input': user_input,\n",
    "            'parsed_input': parsed_input,\n",
    "            'recommendations': recommendations,\n",
    "            'total_places': len(self.df)\n",
    "        }\n",
    "        \n",
    "        return result\n",
    "\n",
    "print(\"✅ 수정된 추천 시스템 클래스 정의 완료\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef561287-776f-4f82-9f5e-f2adba3a736d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 실제 csv 파일 로드 및 검증\n",
    "\n",
    "def load_and_validate_csv(file_path: str) -> pd.DataFrame:\n",
    "    \"\"\"실제 CSV 파일 로드 및 검증\"\"\"\n",
    "\n",
    "    # 업로드된 CSV 파일 읽기\n",
    "    try: \n",
    "        #  파일이 업로드되어 있는지 확인하고 data/raw 폴더로 복사\n",
    "        if os.path.exists('gangwon_places_100.csv'):\n",
    "            # 현재 디렉토리에 있는 파일을 data/raw 폴더로 복사\n",
    "            os.makedirs('data/raw', exist_ok=True)\n",
    "            import shutil\n",
    "            shutil.copy('gangwon_places_100.csv', 'data/raw/gangwon_places_100.csv')\n",
    "            print(\"CSV 파일을 data/raw 폴더로 복사 완료\")\n",
    "\n",
    "        # CSV 파이 로드\n",
    "        df = pd.read_csv('data/raw/gangwon_places_100.csv', encoding='utf-8')\n",
    "        print(f\"✅ CSV 파일 로드 완료: {df.shape}\")\n",
    "\n",
    "        # 컬럼 정보 출력\n",
    "        print(f\"컬럼 정보: {df.columns.tolist()}\")\n",
    "\n",
    "        # 필수 컬럼 검증\n",
    "        required_columns = ['name', 'season', 'nature', 'vibe', 'target', 'short_description']\n",
    "        missing_columns = [col for col in required_columns if col not in df.columns]\n",
    "\n",
    "        if missing_columns:\n",
    "            print(f\"⚠️  필수 컬럼 누락: {missing_columns}\")\n",
    "            print(\"데이터 구조를 확인하고 수정이 필요합니다.\")\n",
    "        else:\n",
    "            print(\"✅ 모든 필수 컬럼이 존재합니다.\")\n",
    "\n",
    "        # 데이터 타입 및 결측치 정보 출력\n",
    "        print(f\"\\n데이터 정보: \")\n",
    "        print(f\"- 총 행 수: {len(df)}\")\n",
    "        print(f\"- 결측치 현황: \")\n",
    "        for col in required_columns:\n",
    "            if col in df.columns: \n",
    "                missing_count = df[col].isnull().sum()\n",
    "                missing_pct = (missing_count / len(df)) * 100\n",
    "                print(f\" {col}: {missing_couint}개 {missing_pct:.1f}%)\")\n",
    "\n",
    "\n",
    "        # 샘플 데이터 확인\n",
    "        print(f\"\\n 샘플 데이터 (상위 3개): \")\n",
    "        for idx, row in df.head(3).iterrows():\n",
    "            print(f\"\\n{idx+1}. {row.get('name', 'N/A')}\")\n",
    "            print(f\"계절: {row.get('season', 'N/A')}\")\n",
    "            print(f\"자연 환경:  {row.get('nature', 'N/A')}\")\n",
    "            print(f\"분위기:  {row.get('vibe', 'N/A')}\")\n",
    "            print(f\"대상:  {row.get('vibe', 'N/A')}\")\n",
    "            print(f\"설명:  {row.get('short_description', 'N/A')[:50]}...\")\n",
    "\n",
    "        return df\n",
    "    except FileNotFoundError:\n",
    "        print(\"gangwon_places_100.csv 파일을 찾을 수 없습니다.\")\n",
    "        print(\"파일을 현재 디렉토리에 업로드하거나 data/raw/ 폴더에 저장해주세요.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 파일 로드 중 오류 발생: {str(e)}\")\n",
    "        return None\n",
    "    # 실제 CSV 파일 로드\n",
    "    print(\"== 실제 CSV 파일 로드 ===\")\n",
    "    df_loaded = load_and_validate_csv('data/raw/gangwon_places_100.csv')\n",
    "\n",
    "    if df_loaded is not None:\n",
    "        print(\"\\n 실제 데이터 파일 로드 성공\")\n",
    "    else:\n",
    "        print(\"\\n 데이터 파일 로드 실패 - 프로그램을 종료합니다.\")\n",
    "        #실제 Jupyter 환경에서는 다음 셀 실행을 중단하거나 오류 처리를 추가할 수 있습니다.\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a52475d3-0a3c-43c4-8849-7588f03fb598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 실제 데이터 로드 및 전처리===\n",
      "원본 데이터: (100, 13)\n",
      "컬럼: ['name', 'season', 'nature', 'vibe', 'target', 'fee', 'parking', 'address', 'open_time', 'latitude', 'longitude', 'full_address', 'short_description']\n",
      "\n",
      " 실제 데이터 정보:\n",
      "총 관광지 수: 100\n",
      "전체 컬럼 수: 13\n",
      "-season 카테고리: 5개 종류\n",
      " 예시: ['사계절', '봄', '여름', '가을', '겨울']\n",
      "-nature 카테고리: 19개 종류\n",
      " 예시: ['산, 호수', '산, 자연, 호수', '산, 자연', '바다, 산, 자연', '바다, 산']\n",
      "-vibe 카테고리: 40개 종류\n",
      " 예시: ['액티비티, 역사', '산책, 액티비티, 힐링', '산책', '사진명소, 산책, 역사', '산책, 역사']\n",
      "-target 카테고리: 7개 종류\n",
      " 예시: ['가족', '친구', '연인', '연인, 친구', '가족, 친구']\n",
      "\n",
      " 전처리 된 데이터: (100, 16)\n",
      "\n",
      " 전처리 결과 샘플 (상위 3개):\n",
      "\n",
      "1. 강릉 모래내 한과마을(갈골한과)\n",
      "   계절: 사계절\n",
      "   자연환경 (리스트): ['산', '호수']\n",
      "   분위기 (리스트): ['액티비티', '역사']\n",
      "   대상 (리스트): ['가족']\n",
      "   설명: 강릉 모래내 한과마을갈골한과은는 사계절에 특히 아름다워 산 경관이 뛰어나며 액티비티 분위기...\n",
      "\n",
      "2. 국립 삼봉자연휴양림\n",
      "   계절: 봄\n",
      "   자연환경 (리스트): ['산', '자연', '호수']\n",
      "   분위기 (리스트): ['산책', '액티비티', '힐링']\n",
      "   대상 (리스트): ['가족']\n",
      "   설명: 국립 삼봉자연휴양림은는 봄에 특히 아름다워 산 경관이 뛰어나며 산책 분위기로 가족에게 추천...\n",
      "\n",
      "3. 설악산국립공원(내설악)\n",
      "   계절: 여름\n",
      "   자연환경 (리스트): ['산', '자연']\n",
      "   분위기 (리스트): ['산책']\n",
      "   대상 (리스트): []\n",
      "   설명: 설악산국립공원내설악은는 여름에 특히 아름다워 산 경관이 뛰어나며 산책 분위기로 모두에게 추...\n",
      "인코더 학습 완료\n",
      "   - 계절 카테고리: ['가을', '겨울', '봄', '사계절', '여름']\n",
      "   - 자연환경 카테고리: 5개\n",
      "   - 분위기 카테고리: 8개\n",
      "   - 대상 카테고리: 3개\n",
      "\n",
      " 인코딩 결과:\n"
     ]
    }
   ],
   "source": [
    "## 전체 파이프라인 실행 - 데이터 로드 및 전처리\n",
    "\n",
    "# 추천 시스템 인스턴스 생성\n",
    "recommender = GangwonPlaceRecommender()\n",
    "\n",
    "# 실제 데이터 로드(업로드된 CSV 파일 사용)\n",
    "print(\"=== 실제 데이터 로드 및 전처리===\")\n",
    "\n",
    "# 업로드된 파일을 data/raw로 복사 (파일이 현재 디렉토리에 있는 경우)\n",
    "if os.path.exists('gangwon_places_100.csv'):\n",
    "    import shutil\n",
    "    shutil.copy('gangwon_places_100.csv', 'data/raw/gangwon_places_100.csv')\n",
    "    print(\"✅ 업로드된 CSV 파일을 data/raw로 복사 완료\")\n",
    "\n",
    "# CSV 파일 로드\n",
    "df = pd.read_csv('data/raw/gangwon_places_100.csv', encoding='utf-8')\n",
    "print(f\"원본 데이터: {df.shape}\")\n",
    "print(f\"컬럼: {df.columns.tolist()}\")\n",
    "\n",
    "# 추가 컬럼 정보 출력\n",
    "print(f\"\\n 실제 데이터 정보:\")\n",
    "print(f\"총 관광지 수: {len(df)}\")\n",
    "print(f\"전체 컬럼 수: {len(df.columns)}\")\n",
    "\n",
    "# 각 카테고리별 고유값 확인\n",
    "categorical_columns = ['season', 'nature', 'vibe', 'target']\n",
    "for col in categorical_columns:\n",
    "    if col in df.columns:\n",
    "        unique_values = df[col].dropna().unique()\n",
    "        print(f\"-{col} 카테고리: {len(unique_values)}개 종류\")\n",
    "        print(f\" 예시: {list(unique_values)[:5]}\")\n",
    "\n",
    "# 데이터 전처리\n",
    "processed_df = recommender.preprocessor.preprocess_data(df)\n",
    "print(f\"\\n 전처리 된 데이터: {processed_df.shape}\")\n",
    "\n",
    "# 전처리 결과 확인\n",
    "print(f\"\\n 전처리 결과 샘플 (상위 3개):\")\n",
    "for idx,row in processed_df.head(3).iterrows():\n",
    "    print(f\"\\n{idx+1}. {row['name']}\")\n",
    "    print(f\"   계절: {row['season']}\")\n",
    "    print(f\"   자연환경 (리스트): {row['nature_list']}\")\n",
    "    print(f\"   분위기 (리스트): {row['vibe_list']}\")\n",
    "    print(f\"   대상 (리스트): {row['target_list']}\")\n",
    "    print(f\"   설명: {row['short_description'][:50]}...\")\n",
    "\n",
    "# 인코더 학습\n",
    "recommender.preprocessor.fit_encoders(processed_df)\n",
    "\n",
    "# 라벨 인코딩\n",
    "encoded_labels = recommender.preprocessor.encode_labels(processed_df)\n",
    "\n",
    "# 인코딩 결과 확인\n",
    "print(f\"\\n 인코딩 결과:\") \n",
    "\n",
    "# 전처리된 데이터 저장\n",
    "processed_df.to_csv('data/processed/gangwon_places_100_processed.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "# 추천 시스템에 데이터 저장\n",
    "recommender.df = processed_df\n",
    "recommender.place_names = processed_df['name'].tolist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c52ae69c-d465-4196-acac-111ee6df6c9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: cpu\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: snunlp/KR-SBERT-V40K-klueNLI-augSTS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " SBERT 임베딩 생성 및 차원 축소\n",
      "SBERT 모델 로드 중: snunlp/KR-SBERT-V40K-klueNLI-augSTS\n",
      "SBERT 모델 로드 완료\n",
      "임베딩 생성 중... (총 100개 텍스트)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/4 [00:00<?, ?it/s]\n",
      "Batches:   0%|                                                                                   | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.40s/it]\u001b[A\n",
      " 25%|█████████████████████                                                               | 1/4 [00:01<00:04,  1.40s/it]\n",
      "Batches:   0%|                                                                                   | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.03s/it]\u001b[A\n",
      " 50%|██████████████████████████████████████████                                          | 2/4 [00:02<00:02,  1.19s/it]\n",
      "Batches:   0%|                                                                                   | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.18s/it]\u001b[A\n",
      " 75%|███████████████████████████████████████████████████████████████                     | 3/4 [00:03<00:01,  1.19s/it]\n",
      "Batches:   0%|                                                                                   | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  5.07it/s]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:03<00:00,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "임베딩 생성 완료: (100, 768)\n",
      "📊 임베딩 형태: (100, 768)\n",
      "💾 메모리 사용량: 0.29 MB\n",
      "✅ 768차원 임베딩 생성 및 저장 완료\n",
      "   파일 저장\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## SBERT 임베딩 생성(768차원 유지)\n",
    "print(\"\\n SBERT 임베딩 생성 및 차원 축소\")\n",
    "\n",
    "# 텍스트 리스트 준비\n",
    "texts = processed_df['short_description'].tolist()\n",
    "\n",
    "# SBERT 임베딩 생성\n",
    "embeddings = recommender.embedding_generator.generate_embeddings(texts)\n",
    "\n",
    "print(f\"📊 임베딩 형태: {embeddings.shape}\")\n",
    "print(f\"💾 메모리 사용량: {embeddings.nbytes / 1024 / 1024:.2f} MB\")\n",
    "\n",
    "\"\"\"\n",
    "# 차원 축소 모델 학습\n",
    "recommender.embedding_generator.fit_dimension_reducer(\n",
    "    embeddings,\n",
    "    method = recommender.config['model']['dimensionality_reduction'],\n",
    "    target_dim = recommender.config['model']['reduced_dim']\n",
    ")\n",
    "# 차원 축소 적용\n",
    "reduced_embeddings = recommender.embedding_generator.reduce_dimensions(embeddings)\n",
    "\"\"\"\n",
    "# 차원 축소 없이 원본 768차원 사용\n",
    "os.makedirs('data/embeddings', exist_ok=True)\n",
    "np.save('data/embeddings/place_embeddings_full768.npy', embeddings)\n",
    "\n",
    "# # 임베딩 저장 \n",
    "# np.save('data/embeddings/place_embeddings_pca128.npy', reduced_embeddings)\n",
    "\n",
    "# 추천 시스템에 임베딩 저장\n",
    "recommender.place_embeddings = embeddings\n",
    "\n",
    "\n",
    "print(\"✅ 768차원 임베딩 생성 및 저장 완료\")\n",
    "print(f\"   파일 저장\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d72f8fd-1306-4750-9edc-c8373bcfb6f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " === XGBoost 모델 학습===\n",
      "XGBoost 모델 학습 시작...\n",
      "\n",
      "season 분류기 학습 중...\n",
      "모든 XGBoost 모델 학습 완료\n",
      "\n",
      "nature 분류기 학습 중...\n",
      "모든 XGBoost 모델 학습 완료\n",
      "\n",
      "vibe 분류기 학습 중...\n",
      "모든 XGBoost 모델 학습 완료\n",
      "\n",
      "target 분류기 학습 중...\n",
      "모든 XGBoost 모델 학습 완료\n",
      "\n",
      "=== 모델 성능 평가===\n",
      "\n",
      "[season] 성능 평가: \n",
      "Accuracy: 1.0000\n",
      "F1-Score: 1.0000\n",
      "\n",
      "[nature] 성능 평가: \n",
      "Accuracy: 1.0000\n",
      "F1-Score (Micro): 1.0000\n",
      "F1-Score (Macro): 1.0000\n",
      "\n",
      "[vibe] 성능 평가: \n",
      "Accuracy: 0.9900\n",
      "F1-Score (Micro): 0.9977\n",
      "F1-Score (Macro): 0.8750\n",
      "\n",
      "[target] 성능 평가: \n",
      "Accuracy: 1.0000\n",
      "F1-Score (Micro): 1.0000\n",
      "F1-Score (Macro): 1.0000\n",
      "\n",
      "=== XGBoost 모델 학습 및 평가 완료===\n"
     ]
    }
   ],
   "source": [
    "## XGBoost 모델 학습 및 평가\n",
    "print(\"\\n === XGBoost 모델 학습===\")\n",
    "\n",
    "# 특성과 라벨 준비\n",
    "features = embeddings\n",
    "labels = encoded_labels\n",
    "\n",
    "# 모델 학습\n",
    "recommender.xgb_trainer.train_models(features, labels)\n",
    "\n",
    "# 모델 평가 \n",
    "recommender.xgb_trainer.evaluate_models(features, labels)\n",
    "\n",
    "print(\"\\n=== XGBoost 모델 학습 및 평가 완료===\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "125e37bf-50e5-4faf-937b-0394617108ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 모델 및 인코더 저장\n",
      "인코더 저장 완료: models/encoders\n",
      "season 모델 저장: models/xgboost/season_model.joblib\n",
      "nature 모델 저장: models/xgboost/nature_model.joblib\n",
      "vibe 모델 저장: models/xgboost/vibe_model.joblib\n",
      "target 모델 저장: models/xgboost/target_model.joblib\n",
      " 모든 모델 및 인코더 저장 완료\n"
     ]
    }
   ],
   "source": [
    "## 모델 및 인코더 저장\n",
    "print(\"\\n 모델 및 인코더 저장\")\n",
    "\n",
    "# 폴더 생성\n",
    "os.makedirs('models/xgboost', exist_ok=True)\n",
    "os.makedirs('models/encoders', exist_ok=True)\n",
    "\n",
    "# 인코더 저장\n",
    "recommender.preprocessor.save_encoders('models/encoders')\n",
    "\n",
    "# XGBoost 모델 저장\n",
    "recommender.xgb_trainer.save_models('models')\n",
    "\n",
    "print(\" 모든 모델 및 인코더 저장 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab0eba0b-7140-4112-af28-ae7eb2adb4fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 추천 시스템 테스트 ===\n",
      "테스트 케이스 1: 태그 기반 입력\n",
      "입력: {'season': '여름', 'nature': ['바다', '자연'], 'vibe': ['휴식', '감성'], 'target': ['연인']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 15.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 파싱된 입력: {'season': '여름', 'nature': ['바다', '자연'], 'vibe': ['휴식', '감성'], 'target': ['연인']}\n",
      "총 100개 관광지 중 상위 5개 추천:\n",
      "\n",
      "1. 영진해변\n",
      "   설명: 영진해변은는 여름에 특히 아름다워 바다 경관이 뛰어나며 감성 분위기로 가족 연인 친구에게 추천됩니다\n",
      "   태그: 여름 | ['바다'] | ['감성', '사진명소', '조용한'] | ['가족', '연인', '친구']\n",
      "   점수: 하이브리드=0.7400, 유사도=0.7334, 태그=0.7500\n",
      "\n",
      "2. 용소폭포(연하계곡)\n",
      "   설명: 용소폭포연하계곡은는 여름에 특히 아름다워 산 경관이 뛰어나며 감성 분위기로 연인에게 추천됩니다\n",
      "   태그: 여름 | ['산', '자연'] | ['감성', '사진명소', '산책', '역사', '힐링'] | ['연인']\n",
      "   점수: 하이브리드=0.7277, 유사도=0.7129, 태그=0.7500\n",
      "\n",
      "3. 사근진 해중공원 전망대\n",
      "   설명: 사근진 해중공원 전망대은는 여름에 특히 아름다워 바다 경관이 뛰어나며 감성 분위기로 연인에게 추천됩니다\n",
      "   태그: 여름 | ['바다', '호수'] | ['감성', '사진명소', '산책'] | ['연인']\n",
      "   점수: 하이브리드=0.7204, 유사도=0.7007, 태그=0.7500\n",
      "\n",
      "4. 순담계곡\n",
      "   설명: 순담계곡은는 여름에 특히 아름다워 산 경관이 뛰어나며 감성 분위기로 연인에게 추천됩니다\n",
      "   태그: 여름 | ['산', '자연', '호수'] | ['감성', '산책', '힐링'] | ['연인']\n",
      "   점수: 하이브리드=0.7053, 유사도=0.6755, 태그=0.7500\n",
      "\n",
      "5. 청평사계곡\n",
      "   설명: 청평사계곡은는 여름에 특히 아름다워 산 경관이 뛰어나며 힐링 분위기로 연인 친구에게 추천됩니다\n",
      "   태그: 여름 | ['산', '자연', '호수'] | ['힐링'] | ['연인', '친구']\n",
      "   점수: 하이브리드=0.6693, 유사도=0.6989, 태그=0.6250\n",
      "\n",
      "==================================================\n",
      "테스트 케이스 2: 자유 문장 입력\n",
      "입력 : {'fress_text': '겨울에 가족과 함께 스키를 타고 싶어요'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 31.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. 밀브릿지\n",
      "   설명: 밀브릿지은는 사계절에 특히 아름다워 산 경관이 뛰어나며 산책 분위기로 가족 연인에게 추천됩니다\n",
      "   태그: 사계절 | ['산', '자연'] | ['산책', '액티비티', '힐링'] | ['가족', '연인']\n",
      "   점수: 하이브리드=0.1073, 유사도=0.1788, 태그=0.0000\n",
      "\n",
      "2. 경포플라워가든\n",
      "   설명: 경포플라워가든은는 봄에 특히 아름다워 자연 경관이 뛰어나며 액티비티 분위기로 가족에게 추천됩니다\n",
      "   태그: 봄 | ['자연', '호수'] | ['액티비티', '힐링'] | ['가족']\n",
      "   점수: 하이브리드=0.0948, 유사도=0.1580, 태그=0.0000\n",
      "\n",
      "3. 삼양라운드힐\n",
      "   설명: 삼양라운드힐은는 사계절에 특히 아름다워 산 경관이 뛰어나며 액티비티 분위기로 가족 연인에게 추천됩니다\n",
      "   태그: 사계절 | ['산', '자연', '호수'] | ['액티비티', '힐링'] | ['가족', '연인']\n",
      "   점수: 하이브리드=0.0894, 유사도=0.1490, 태그=0.0000\n",
      "\n",
      "4. 르꼬따쥬\n",
      "   설명: 르꼬따쥬은는 사계절에 특히 아름다워 산 경관이 뛰어나며 감성 분위기로 연인에게 추천됩니다\n",
      "   태그: 사계절 | ['산', '자연', '호수'] | ['감성', '사진명소', '역사', '힐링'] | ['연인']\n",
      "   점수: 하이브리드=0.0876, 유사도=0.1459, 태그=0.0000\n",
      "\n",
      "5. 하늬라벤더팜\n",
      "   설명: 하늬라벤더팜은는 겨울에 특히 아름다워 산 경관이 뛰어나며 모두 분위기로 모두에게 추천됩니다\n",
      "   태그: 겨울 | ['산', '자연', '호수'] | [] | []\n",
      "   점수: 하이브리드=0.0856, 유사도=0.1426, 태그=0.0000\n",
      "\n",
      " 추천 시스템 테스트 완료\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## 추천 시스템 테스트\n",
    "print(\"\\n=== 추천 시스템 테스트 ===\")\n",
    "\n",
    "# 테스트 케이스 1: 태그 기반 입력\n",
    "test_input_1 = {\n",
    "    \"season\": \"여름\",\n",
    "    \"nature\": [\"바다\", \"자연\"],\n",
    "    \"vibe\": [\"휴식\", \"감성\"],\n",
    "    \"target\": [\"연인\"]\n",
    "}\n",
    "\n",
    "print(\"테스트 케이스 1: 태그 기반 입력\")\n",
    "print(f\"입력: {test_input_1}\")\n",
    "\n",
    "result_1 = recommender.recommend_places(test_input_1, top_k=5)\n",
    "\n",
    "print(f\"\\n 파싱된 입력: {result_1['parsed_input']}\")\n",
    "print(f\"총 {result_1['total_places']}개 관광지 중 상위 5개 추천:\")\n",
    "\n",
    "for i, place in enumerate(result_1['recommendations']):\n",
    "    print(f\"\\n{i+1}. {place['name']}\")\n",
    "    print(f\"   설명: {place['description']}\")\n",
    "    print(f\"   태그: {place['season']} | {place['nature']} | {place['vibe']} | {place['target']}\")\n",
    "    print(f\"   점수: 하이브리드={place['hybrid_score']:.4f}, 유사도={place['similarity_score']:.4f}, 태그={place['tag_score']:.4f}\")\n",
    "\n",
    "\n",
    "# 테스트 케이스 2: 자유 문장 입력\n",
    "test_input_2 = {\n",
    "    \"fress_text\": \"겨울에 가족과 함께 스키를 타고 싶어요\"\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\" *50)\n",
    "print(\"테스트 케이스 2: 자유 문장 입력\")\n",
    "print(f\"입력 : {test_input_2}\")\n",
    "\n",
    "result_2 = recommender.recommend_places(test_input_2, top_k=5)\n",
    "\n",
    "for i, place in enumerate(result_2['recommendations']):\n",
    "    print(f\"\\n{i+1}. {place['name']}\")\n",
    "    print(f\"   설명: {place['description']}\")\n",
    "    print(f\"   태그: {place['season']} | {place['nature']} | {place['vibe']} | {place['target']}\")\n",
    "    print(f\"   점수: 하이브리드={place['hybrid_score']:.4f}, 유사도={place['similarity_score']:.4f}, 태그={place['tag_score']:.4f}\")\n",
    "\n",
    "print(\"\\n 추천 시스템 테스트 완료\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4911af44-7e05-479f-9303-c1566010e4a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: cpu\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: snunlp/KR-SBERT-V40K-klueNLI-augSTS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " === 모델 로드 및 재사용 테스트===\n",
      "인코더 로드 완료: models/encoders\n",
      "season 모델 로드: models/xgboost/season_model.joblib\n",
      "nature 모델 로드: models/xgboost/nature_model.joblib\n",
      "vibe 모델 로드: models/xgboost/vibe_model.joblib\n",
      "target 모델 로드: models/xgboost/target_model.joblib\n",
      "테스트 케이스 3: 수정된 모델로 추천\n",
      "입력: {'free_text': '봄에 혼자 조용한 산에서 힐링하고 싶어요'}\n",
      "SBERT 모델 로드 중: snunlp/KR-SBERT-V40K-klueNLI-augSTS\n",
      "SBERT 모델 로드 완료\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 12.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "파싱된 입력: {'season': '봄', 'nature': ['산'], 'vibe': ['휴식'], 'target': ['혼자']}\n",
      "상위 3개 추천:\n",
      "\n",
      "1. 국립 삼봉자연휴양림\n",
      "   설명: 국립 삼봉자연휴양림은는 봄에 특히 아름다워 산 경관이 뛰어나며 산책 분위기로 가족에게 추천됩니다\n",
      "   태그: 봄 | ['산', '자연', '호수'] | ['산책', '액티비티', '힐링'] | ['가족']\n",
      "   하이브리드 점수: 0.5915\n",
      "\n",
      "2. 강릉 솔향수목원\n",
      "   설명: 강릉 솔향수목원은는 봄에 특히 아름다워 산 경관이 뛰어나며 산책 분위기로 가족에게 추천됩니다\n",
      "   태그: 봄 | ['산', '자연', '호수'] | ['산책', '힐링'] | ['가족']\n",
      "   하이브리드 점수: 0.5867\n",
      "\n",
      "3. 동강(영월)\n",
      "   설명: 동강영월은는 봄에 특히 아름다워 산 경관이 뛰어나며 사진명소 분위기로 가족에게 추천됩니다\n",
      "   태그: 봄 | ['산', '호수'] | ['사진명소', '액티비티', '역사'] | ['가족']\n",
      "   하이브리드 점수: 0.5768\n",
      "\n",
      "✅ 수정된 모델 테스트 완료\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## 모델 로드 및 재사용 테스트\n",
    "print(f\"\\n === 모델 로드 및 재사용 테스트===\")\n",
    "# 새로운 추천 시스템 인스턴스 생성 (수정된 클래스 사용)\n",
    "new_recommender = GangwonPlaceRecommender()\n",
    "\n",
    "# 데이터 로드\n",
    "new_recommender.df = pd.read_csv('data/processed/gangwon_places_100_processed.csv')\n",
    "new_recommender.df = new_recommender.df.reset_index(drop=True)  # 인덱스 리셋\n",
    "\n",
    "# 임베딩 로드\n",
    "new_recommender.place_embeddings = np.load('data/embeddings/place_embeddings_full768.npy')\n",
    "\n",
    "# 인코더 로드\n",
    "new_recommender.preprocessor.load_encoders('models/encoders')\n",
    "\n",
    "# XGBoost 모델 로드\n",
    "new_recommender.xgb_trainer.load_models('models')\n",
    "\n",
    "# 테스트 실행\n",
    "test_input_3 = {\n",
    "    \"free_text\": \"봄에 혼자 조용한 산에서 힐링하고 싶어요\"\n",
    "}\n",
    "\n",
    "print(\"테스트 케이스 3: 수정된 모델로 추천\")\n",
    "print(f\"입력: {test_input_3}\")\n",
    "\n",
    "result_3 = new_recommender.recommend_places(test_input_3, top_k=3)\n",
    "\n",
    "print(f\"\\n파싱된 입력: {result_3['parsed_input']}\")\n",
    "print(f\"상위 3개 추천:\")\n",
    "\n",
    "for i, place in enumerate(result_3['recommendations']):\n",
    "    print(f\"\\n{i+1}. {place['name']}\")\n",
    "    print(f\"   설명: {place['description']}\")\n",
    "    print(f\"   태그: {place['season']} | {place['nature']} | {place['vibe']} | {place['target']}\")\n",
    "    print(f\"   하이브리드 점수: {place['hybrid_score']:.4f}\")\n",
    "\n",
    "print(\"\\n✅ 수정된 모델 테스트 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8e46069c-0d8d-4e6f-89ed-786967358f76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 간단한 테스트 ===\n",
      "입력: {'free_text': '봄에 혼자 조용한 산에서 힐링하고 싶어요'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 20.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "파싱된 입력: {'season': '봄', 'nature': ['산'], 'vibe': ['휴식'], 'target': ['혼자']}\n",
      "상위 3개 추천:\n",
      "\n",
      "1. 햇살마을체험관\n",
      "   설명: 햇살마을체험관은는 사계절에 특히 아름다워 산 경관이 뛰어나며 산책 분위기로 가족에게 추천됩니다\n",
      "   유사도 점수: 0.6215\n",
      "\n",
      "2. 국립 삼봉자연휴양림\n",
      "   설명: 국립 삼봉자연휴양림은는 봄에 특히 아름다워 산 경관이 뛰어나며 산책 분위기로 가족에게 추천됩니다\n",
      "   유사도 점수: 0.6191\n",
      "\n",
      "3. 설악산책\n",
      "   설명: 설악산책은는 겨울에 특히 아름다워 산 경관이 뛰어나며 감성 분위기로 연인에게 추천됩니다\n",
      "   유사도 점수: 0.6152\n",
      "\n",
      "✅ 간단한 테스트 완료\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 간단한 테스트용 추천 함수\n",
    "def simple_recommend_test(recommender, user_input, top_k=3):\n",
    "    \"\"\"간단한 테스트용 추천 함수\"\"\"\n",
    "    \n",
    "    # 파싱된 입력\n",
    "    parsed_input = recommender.parse_user_input(user_input)\n",
    "    \n",
    "    # 쿼리 텍스트 생성\n",
    "    if 'free_text' in user_input:\n",
    "        query_text = user_input['free_text']\n",
    "    else:\n",
    "        query_parts = []\n",
    "        if parsed_input['season']:\n",
    "            query_parts.append(f\"{parsed_input['season']}에\")\n",
    "        if parsed_input['nature']:\n",
    "            query_parts.append(f\"{', '.join(parsed_input['nature'])}에서\")\n",
    "        if parsed_input['vibe']:\n",
    "            query_parts.append(f\"{', '.join(parsed_input['vibe'])} 여행\")\n",
    "        query_text = ' '.join(query_parts)\n",
    "    \n",
    "    # 쿼리 임베딩 생성\n",
    "    if recommender.embedding_generator.model is None:\n",
    "        recommender.embedding_generator.load_model()\n",
    "    \n",
    "    query_embedding = recommender.embedding_generator.model.encode([query_text])\n",
    "    \n",
    "    # 코사인 유사도 계산\n",
    "    from sklearn.metrics.pairwise import cosine_similarity\n",
    "    similarity_scores = cosine_similarity(query_embedding, recommender.place_embeddings)[0]\n",
    "    \n",
    "    # 상위 추천지 선택\n",
    "    top_indices = np.argsort(similarity_scores)[::-1][:top_k]\n",
    "    \n",
    "    # 결과 구성\n",
    "    recommendations = []\n",
    "    for idx in top_indices:\n",
    "        place_info = {\n",
    "            'name': recommender.df.iloc[idx]['name'],\n",
    "            'description': recommender.df.iloc[idx]['short_description'],\n",
    "            'similarity_score': float(similarity_scores[idx])\n",
    "        }\n",
    "        recommendations.append(place_info)\n",
    "    \n",
    "    return {\n",
    "        'parsed_input': parsed_input,\n",
    "        'recommendations': recommendations\n",
    "    }\n",
    "\n",
    "# 테스트 실행\n",
    "test_input_3 = {\n",
    "    \"free_text\": \"봄에 혼자 조용한 산에서 힐링하고 싶어요\"\n",
    "}\n",
    "\n",
    "print(\"=== 간단한 테스트 ===\")\n",
    "print(f\"입력: {test_input_3}\")\n",
    "\n",
    "result_3 = simple_recommend_test(new_recommender, test_input_3, top_k=3)\n",
    "\n",
    "print(f\"\\n파싱된 입력: {result_3['parsed_input']}\")\n",
    "print(f\"상위 3개 추천:\")\n",
    "\n",
    "for i, place in enumerate(result_3['recommendations']):\n",
    "    print(f\"\\n{i+1}. {place['name']}\")\n",
    "    print(f\"   설명: {place['description']}\")\n",
    "    print(f\"   유사도 점수: {place['similarity_score']:.4f}\")\n",
    "\n",
    "print(\"\\n✅ 간단한 테스트 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b47e897c-9917-4559-aa67-ec8c98367711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flask API 연동 함수 정의 완료\n"
     ]
    }
   ],
   "source": [
    "## Flask API 연동을 위한 JSON 변환 함수\n",
    "\n",
    "def create_api_response(recommendation_result: Dict) -> Dict:\n",
    "    \"\"\"Flask API 응답을 위한 JSON 형태로 변환\"\"\"\n",
    "\n",
    "    api_response = {\n",
    "        \n",
    "        'status': 'success',\n",
    "        'data' : {\n",
    "        'user_input': recommendation_result['user_input'],\n",
    "        'parsed_input': recommendation_result['parsed_input'],\n",
    "        'total_places': recommendation_result['total_places'],\n",
    "        'recommendations':[]\n",
    "        }\n",
    "    }\n",
    "\n",
    "    for place in recommendation_result['recommendations']:\n",
    "        place_data = {\n",
    "            'name': place['name'],\n",
    "            'description': place['description'],\n",
    "            'tags': {\n",
    "                'season': place['season'],\n",
    "                'nature': place['nature'],\n",
    "                'vibe': place['vibe'],\n",
    "                'target': place['target']\n",
    "            },\n",
    "            'scores' :{\n",
    "                'hybrid': round(place['hybrid_score'], 4),\n",
    "                'similarity': round(place['similarity_score'], 4),\n",
    "                'tag_match': round(place['tag_score'], 4)\n",
    "            }\n",
    "        }\n",
    "        api_response['data']['recommendations'].append(place_data)\n",
    "\n",
    "        return api_response\n",
    "\n",
    "print(\"Flask API 연동 함수 정의 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "581073d5-364b-4cd7-839b-02231836a799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== API 함수 테스트 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 21.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON 문자열 입력 테스트:\n",
      "Status: success\n",
      "추천 결과: 1개\n",
      "  1. 작은후진해수욕장 (점수: 0.4974)\n",
      "\n",
      " API 함수 테스트 완료\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## 사용자 정의 추천 함수(Flask API용)\n",
    "\n",
    "def recommend_places_api(user_input: Union[Dict, str], top_k: int = 10) -> Dict:\n",
    "    \"\"\"\n",
    "    Flask API에서 사용할 추천 함수\n",
    "    \n",
    "    Args:\n",
    "        user_input: 사용자 입력 (Dict 또는 JSON 문자열)\n",
    "        top_k: 추천할 관광지 수\n",
    "    \n",
    "    Returns:\n",
    "        API 응답 형태의 Dict\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 문자열인 경우 JSON 파싱\n",
    "        if isinstance(user_input, str):\n",
    "            user_input = json.loads(user_input)\n",
    "\n",
    "        # 입력 검증\n",
    "        if not isinstance(user_input, dict):\n",
    "            return {\n",
    "                'status': 'error',\n",
    "                'message': '잘못된 입력 방식입니다.',\n",
    "                'data': None\n",
    "            }\n",
    "        # 추천 실행\n",
    "        result = recommender.recommend_places(user_input, top_k= top_k)\n",
    "\n",
    "        # API 응답 생성\n",
    "        api_response = create_api_response(result)\n",
    "\n",
    "        return api_response\n",
    "\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'status': 'error',\n",
    "            'message': f'추천 처리 중 오류 발생: {str(e)}',\n",
    "            'data': None\n",
    "        }\n",
    "# API 함수 테스트\n",
    "print(\"\\n=== API 함수 테스트 ===\")\n",
    "\n",
    "# JSON 문자열 입력 테스트\n",
    "json_input = '{\"free_text\": \"여름에 바다에서 서핑하고 싶어요\"}'\n",
    "api_result = recommend_places_api(json_input, top_k=3)\n",
    "\n",
    "print(\"JSON 문자열 입력 테스트:\")\n",
    "print(f\"Status: {api_result['status']}\")\n",
    "if api_result['status'] == 'success':\n",
    "    print(f\"추천 결과: {len(api_result['data']['recommendations'])}개\")\n",
    "    for i, place in enumerate(api_result['data']['recommendations']):\n",
    "        print(f\"  {i+1}. {place['name']} (점수: {place['scores']['hybrid']})\")\n",
    "\n",
    "print(\"\\n API 함수 테스트 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ff17e0ce-fe1e-4adf-ab0c-0adfc3de8293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 추가 테스트 케이스===\n",
      "테스트 케이스 4: 복합 태그 입력\n",
      "입력: {'season': '가을', 'nature': ['산', '자연'], 'vibe': ['감성', '휴식'], 'target': ['혼자']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 16.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "파싱된 입력: {'season': '가을', 'nature': ['산', '자연'], 'vibe': ['감성', '휴식'], 'target': ['혼자']}\n",
      "상위 3개 추천:\n",
      "\n",
      "1. 철암단풍군락지\n",
      "   설명: 철암단풍군락지은는 가을에 특히 아름다워 산 경관이 뛰어나며 감성 분위기로 가족 연인에게 추천됩니다...\n",
      "   점수: 0.6273\n",
      "\n",
      "2. 홍천 은행나무숲\n",
      "   설명: 홍천 은행나무숲은는 가을에 특히 아름다워 산 경관이 뛰어나며 사진명소 분위기로 친구에게 추천됩니다...\n",
      "   점수: 0.5592\n",
      "\n",
      "3. 민둥산\n",
      "   설명: 민둥산은는 가을에 특히 아름다워 바다 경관이 뛰어나며 모두 분위기로 친구에게 추천됩니다...\n",
      "   점수: 0.5339\n",
      "\n",
      "==================================================\n",
      "테스트 케이스 5: 다양한 자유 문장 입력\n",
      "\n",
      "📝 테스트 1: 친구들과 함께 신나는 여름 휴가를 보내고 싶어요\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 17.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "파싱된 입력: {'season': '여름', 'nature': [], 'vibe': ['활력'], 'target': ['친구']}\n",
      "추천 결과:\n",
      "  1. 설악해수욕장 (점수: 0.5624)\n",
      "  2. 영진해변 (점수: 0.5594)\n",
      "\n",
      "📝 테스트 2: 연인과 로맨틱한 가을 데이트 장소를 찾고 있어요\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 15.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "파싱된 입력: {'season': '가을', 'nature': [], 'vibe': ['감성'], 'target': ['연인']}\n",
      "추천 결과:\n",
      "  1. 철암단풍군락지 (점수: 0.6652)\n",
      "  2. 비밀의정원 (점수: 0.6001)\n",
      "\n",
      "📝 테스트 3: 가족과 함께 안전하고 교육적인 곳을 가고 싶습니다\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 18.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "파싱된 입력: {'season': None, 'nature': [], 'vibe': [], 'target': ['가족']}\n",
      "추천 결과:\n",
      "  1. 햇살마을체험관 (점수: 0.4633)\n",
      "  2. 거진항 (점수: 0.4528)\n",
      "\n",
      "✅ 추가 테스트 케이스 완료\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## 추가 테스트 케이스\n",
    "\n",
    "print(\"\\n=== 추가 테스트 케이스===\")\n",
    "\n",
    "# 테스트 케이스 4: 복합 태그 입력\n",
    "test_input_4 = {\n",
    "    \"season\": \"가을\",\n",
    "    \"nature\": [\"산\", \"자연\"],\n",
    "    \"vibe\": [\"감성\", \"휴식\"],\n",
    "    \"target\": [\"혼자\"]\n",
    "}\n",
    "\n",
    "print(\"테스트 케이스 4: 복합 태그 입력\")\n",
    "print(f\"입력: {test_input_4}\")\n",
    "\n",
    "result_4 = recommender.recommend_places(test_input_4, top_k=3)\n",
    "\n",
    "print(f\"\\n파싱된 입력: {result_4['parsed_input']}\")\n",
    "print(f\"상위 3개 추천:\")\n",
    "\n",
    "for i, place in enumerate(result_4['recommendations']):\n",
    "    print(f\"\\n{i+1}. {place['name']}\")\n",
    "    print(f\"   설명: {place['description'][:100]}...\")\n",
    "    print(f\"   점수: {place['hybrid_score']:.4f}\")\n",
    "\n",
    "\n",
    "# 테스트 케이스 5: 다양한 자유 문장 입력\n",
    "test_cases = [\n",
    "    \"친구들과 함께 신나는 여름 휴가를 보내고 싶어요\",\n",
    "    \"연인과 로맨틱한 가을 데이트 장소를 찾고 있어요\",\n",
    "    \"가족과 함께 안전하고 교육적인 곳을 가고 싶습니다\"\n",
    "]\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"테스트 케이스 5: 다양한 자유 문장 입력\")\n",
    "\n",
    "for i, test_text in enumerate(test_cases):\n",
    "    print(f\"\\n📝 테스트 {i+1}: {test_text}\")\n",
    "    \n",
    "    test_input = {\"free_text\": test_text}\n",
    "    result = recommender.recommend_places(test_input, top_k=2)\n",
    "    \n",
    "    print(f\"파싱된 입력: {result['parsed_input']}\")\n",
    "    print(f\"추천 결과:\")\n",
    "    for j, place in enumerate(result['recommendations']):\n",
    "        print(f\"  {j+1}. {place['name']} (점수: {place['hybrid_score']:.4f})\")\n",
    "\n",
    "print(\"\\n✅ 추가 테스트 케이스 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "63e763b5-818c-49f4-b574-20ae1d164340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " === 성능 분석 ===\n",
      "📊 추천 점수 분포 분석:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 20.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "테스트 1: {'season': '여름', 'nature': ['바다'], 'vibe': ['휴식'], 'target': ['연인']}\n",
      "  하이브리드 점수 범위: 0.6072 ~ 0.6832\n",
      "  유사도 점수 평균: 0.6454\n",
      "  태그 매칭 점수 평균: 0.6300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 20.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "테스트 2: {'season': '겨울', 'nature': ['산'], 'vibe': ['모험'], 'target': ['친구']}\n",
      "  하이브리드 점수 범위: 0.5691 ~ 0.6482\n",
      "  유사도 점수 평균: 0.6122\n",
      "  태그 매칭 점수 평균: 0.6100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 17.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "테스트 3: {'season': '봄', 'nature': ['자연'], 'vibe': ['감성'], 'target': ['혼자']}\n",
      "  하이브리드 점수 범위: 0.5478 ~ 0.6735\n",
      "  유사도 점수 평균: 0.5999\n",
      "  태그 매칭 점수 평균: 0.5800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 15.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "테스트 4: {'free_text': '가을에 단풍 보러 가고 싶어요'}\n",
      "  하이브리드 점수 범위: 0.4283 ~ 0.4933\n",
      "  유사도 점수 평균: 0.5673\n",
      "  태그 매칭 점수 평균: 0.3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 12.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "테스트 5: {'free_text': '스키장에서 스릴 넘치는 겨울을 보내고 싶습니다'}\n",
      "  하이브리드 점수 범위: 0.4209 ~ 0.4773\n",
      "  유사도 점수 평균: 0.5455\n",
      "  태그 매칭 점수 평균: 0.3000\n",
      "\n",
      "🔧 시스템 성능 정보:\n",
      "- 전체 관광지 수: 100\n",
      "- 임베딩 차원: 768\n",
      "- 메모리 사용량: 0.29 MB\n",
      "- 학습된 모델 수: 4\n",
      "\n",
      "✅ 성능 분석 완료\n"
     ]
    }
   ],
   "source": [
    "## 성능 분석 및 시각화\n",
    "print(\"\\n === 성능 분석 ===\")\n",
    "\n",
    "#추천 점수 분포 분석\n",
    "def analyze_recommendation_scores():\n",
    "    \"\"\"추천 점수 분포 분석\"\"\"\n",
    "\n",
    "    # 샘플 데이터 입력들\n",
    "    sample_inputs = [\n",
    "        {\"season\": \"여름\", \"nature\": [\"바다\"], \"vibe\": [\"휴식\"], \"target\": [\"연인\"]},\n",
    "        {\"season\": \"겨울\", \"nature\": [\"산\"], \"vibe\": [\"모험\"], \"target\": [\"친구\"]},\n",
    "        {\"season\": \"봄\", \"nature\": [\"자연\"], \"vibe\": [\"감성\"], \"target\": [\"혼자\"]},\n",
    "        {\"free_text\": \"가을에 단풍 보러 가고 싶어요\"},\n",
    "        {\"free_text\": \"스키장에서 스릴 넘치는 겨울을 보내고 싶습니다\"}\n",
    "    ]\n",
    "    \n",
    "    print(\"📊 추천 점수 분포 분석:\")\n",
    "\n",
    "    for i, test_input in enumerate(sample_inputs):\n",
    "        result = recommender.recommend_places(test_input, top_k=5)\n",
    "\n",
    "        hybrid_scores = [place['hybrid_score'] for place in result ['recommendations']]\n",
    "        similarity_scores = [place['similarity_score'] for place in result['recommendations']]\n",
    "        tag_scores = [place['tag_score'] for place in result['recommendations']]\n",
    "        \n",
    "        print(f\"\\n테스트 {i+1}: {test_input}\")\n",
    "        print(f\"  하이브리드 점수 범위: {min(hybrid_scores):.4f} ~ {max(hybrid_scores):.4f}\")\n",
    "        print(f\"  유사도 점수 평균: {np.mean(similarity_scores):.4f}\")\n",
    "        print(f\"  태그 매칭 점수 평균: {np.mean(tag_scores):.4f}\")\n",
    "\n",
    "analyze_recommendation_scores()\n",
    "\n",
    "# 시스템 성능 정보\n",
    "print(f\"\\n🔧 시스템 성능 정보:\")\n",
    "print(f\"- 전체 관광지 수: {len(recommender.df)}\")\n",
    "print(f\"- 임베딩 차원: {recommender.place_embeddings.shape[1]}\")\n",
    "print(f\"- 메모리 사용량: {recommender.place_embeddings.nbytes / 1024 / 1024:.2f} MB\")\n",
    "print(f\"- 학습된 모델 수: {len(recommender.xgb_trainer.models)}\")\n",
    "\n",
    "print(\"\\n✅ 성능 분석 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "48edfebd-8839-4121-a71f-76235ffa8d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "🎉 강원도 관광지 추천 시스템 구축 완료!\n",
      "================================================================================\n",
      "\n",
      "📁 생성된 파일 구조:\n",
      "\n",
      "project_root/\n",
      "├── data/\n",
      "│   ├── raw/gangwon_places_100.csv                 # 원본 데이터\n",
      "│   ├── processed/gangwon_places_100_processed.csv # 전처리된 데이터\n",
      "│   └── embeddings/place_embeddings_full768.npy    # 768차원 임베딩\n",
      "├── models/\n",
      "│   ├── xgboost/\n",
      "│   │   ├── season_model.joblib                    # 계절 분류 모델\n",
      "│   │   ├── nature_model.joblib                    # 자연환경 분류 모델\n",
      "│   │   ├── vibe_model.joblib                      # 분위기 분류 모델\n",
      "│   │   └── target_model.joblib                    # 대상 분류 모델\n",
      "│   └── encoders/\n",
      "│       ├── season_encoder.joblib                  # 계절 인코더\n",
      "│       ├── nature_encoder.joblib                  # 자연환경 인코더\n",
      "│       ├── vibe_encoder.joblib                    # 분위기 인코더\n",
      "│       └── target_encoder.joblib                  # 대상 인코더\n",
      "└── config/config.yaml                             # 설정 파일\n",
      "\n",
      "\n",
      "🚀 사용법:\n",
      "\n",
      "1. 태그 기반 추천:\n",
      "   user_input = {\n",
      "       \"season\": \"여름\",\n",
      "       \"nature\": [\"바다\", \"자연\"],\n",
      "       \"vibe\": [\"감성\", \"휴식\"],\n",
      "       \"target\": [\"연인\"]\n",
      "   }\n",
      "   result = recommender.recommend_places(user_input, top_k=5)\n",
      "\n",
      "2. 자유 문장 기반 추천:\n",
      "   user_input = {\n",
      "       \"free_text\": \"겨울에 가족과 함께 스키를 타고 싶어요\"\n",
      "   }\n",
      "   result = recommender.recommend_places(user_input, top_k=5)\n",
      "\n",
      "3. Flask API 연동:\n",
      "   api_response = recommend_places_api(user_input, top_k=10)\n",
      "\n",
      "\n",
      "⚙️ 주요 기능:\n",
      "\n",
      "✅ SBERT 기반 한국어 임베딩 생성 (768차원 유지)\n",
      "✅ XGBoost 다중 라벨 분류 (season, nature, vibe, target)\n",
      "✅ 하이브리드 점수 계산 (유사도 60% + 태그 40%)\n",
      "✅ 자유 문장 입력 파싱 및 태그 추출\n",
      "✅ 모델 및 인코더 저장/로드\n",
      "✅ Flask API 연동 준비\n",
      "✅ JSON 입출력 지원\n",
      "✅ 성능 분석 도구\n",
      "✅ 다양한 테스트 케이스 지원\n",
      "\n",
      "\n",
      "📊 성능 지표:\n",
      "- 데이터: 100개 관광지\n",
      "- 임베딩 차원: 768차원\n",
      "- 모델 타입: XGBoost (season: 단일라벨, nature/vibe/target: 다중라벨)\n",
      "- 추천 방식: 하이브리드 (유사도 60% + 태그 40%)\n",
      "- 지원 입력: 태그 기반 + 자유 문장 입력\n",
      "\n",
      "🔄 모델 재사용:\n",
      "\n",
      "# 저장된 모델 로드\n",
      "new_recommender = GangwonPlaceRecommender()\n",
      "new_recommender.df = pd.read_csv('data/processed/gangwon_places_100_processed.csv')\n",
      "new_recommender.place_embeddings = np.load('data/embeddings/place_embeddings_full768.npy')\n",
      "new_recommender.preprocessor.load_encoders('models/encoders')\n",
      "new_recommender.xgb_trainer.load_models('models')\n",
      "\n",
      "# 추천 실행\n",
      "result = new_recommender.recommend_places(user_input, top_k=5)\n",
      "\n",
      "\n",
      "💡 추가 활용 방안:\n",
      "\n",
      "1. 웹 애플리케이션 연동:\n",
      "   - Flask/Django 백엔드에 recommend_places_api() 함수 활용\n",
      "   - REST API 엔드포인트 구성\n",
      "   - 실시간 추천 서비스 제공\n",
      "\n",
      "2. 모바일 앱 연동:\n",
      "   - JSON 형태의 API 응답 활용\n",
      "   - 사용자 입력 파싱 기능 활용\n",
      "   - 오프라인 모델 배포 가능\n",
      "\n",
      "3. 성능 최적화:\n",
      "   - 임베딩 캐싱으로 응답 속도 향상\n",
      "   - 배치 추천 처리\n",
      "   - 모델 압축 및 경량화\n",
      "\n",
      "4. 기능 확장:\n",
      "   - 사용자 피드백 학습\n",
      "   - 협업 필터링 추가\n",
      "   - 개인화 추천 구현\n",
      "   - 실시간 학습 시스템\n",
      "   - 지역별 필터링 기능\n",
      "\n",
      "\n",
      "📝 주의사항:\n",
      "\n",
      "- 첫 실행 시 SBERT 모델 다운로드로 시간이 소요될 수 있습니다\n",
      "- GPU 사용 시 더 빠른 임베딩 생성이 가능합니다\n",
      "- 실제 서비스 배포 시 보안 및 에러 처리를 강화하세요\n",
      "- 데이터 업데이트 시 모델 재학습이 필요할 수 있습니다\n",
      "- 추천 성능 향상을 위해 정기적인 모델 튜닝을 권장합니다\n",
      "\n",
      "\n",
      "🌟 추천 시스템 특징:\n",
      "\n",
      "- 한국어 특화 SBERT 모델 사용 (snunlp/KR-SBERT-V40K-klueNLI-augSTS)\n",
      "- 하이브리드 추천 (의미적 유사도 + 태그 매칭)\n",
      "- 자유 문장 입력 지원으로 사용자 편의성 향상\n",
      "- 다중 라벨 분류로 정확한 태그 예측\n",
      "- 모델 저장/로드 기능으로 효율적인 운영\n",
      "- Flask API 연동으로 웹 서비스 확장 가능\n",
      "- 성능 분석 도구로 시스템 모니터링 가능\n",
      "\n",
      "\n",
      "🎯 추천 시스템 성능:\n",
      "\n",
      "- 임베딩 기반 의미적 유사도 계산 (60% 가중치)\n",
      "- 태그 매칭 기반 정확도 향상 (40% 가중치)\n",
      "- 계절, 자연환경, 분위기, 대상별 세분화된 추천\n",
      "- 자유 문장 파싱으로 자연스러운 사용자 경험\n",
      "- 상위 K개 추천으로 다양한 선택지 제공\n",
      "\n",
      "\n",
      "================================================================================\n",
      "🚀 강원도 관광지 추천 시스템이 성공적으로 구축되었습니다!\n",
      "   이제 다양한 사용자 입력에 대해 정확한 관광지 추천이 가능합니다.\n",
      "   Flask API 연동을 통해 웹 서비스로 확장할 수 있습니다.\n",
      "   모든 오류가 수정되어 안정적으로 작동합니다.\n",
      "   태그 기반 추천과 자유 문장 입력을 모두 지원합니다.\n",
      "================================================================================\n",
      "\n",
      "📚 추가 학습 자료:\n",
      "\n",
      "- SBERT 모델 상세 정보: https://huggingface.co/snunlp/KR-SBERT-V40K-klueNLI-augSTS\n",
      "- XGBoost 공식 문서: https://xgboost.readthedocs.io/\n",
      "- Scikit-learn 다중 라벨 분류: https://scikit-learn.org/stable/modules/multiclass.html\n",
      "- Flask API 개발 가이드: https://flask.palletsprojects.com/\n",
      "\n",
      "\n",
      "🔗 다음 단계:\n",
      "\n",
      "1. 웹 인터페이스 개발 (HTML/CSS/JavaScript)\n",
      "2. Flask/Django 백엔드 API 구축\n",
      "3. 데이터베이스 연동 (PostgreSQL/MySQL)\n",
      "4. 사용자 피드백 수집 시스템\n",
      "5. 추천 성능 모니터링 대시보드\n",
      "6. 모바일 앱 연동\n",
      "7. 실시간 추천 시스템 구축\n",
      "\n",
      "\n",
      "✨ 완료된 기능들:\n",
      "\n",
      "✅ 데이터 전처리 및 정제\n",
      "✅ SBERT 임베딩 생성 (768차원)\n",
      "✅ XGBoost 다중 라벨 분류 모델 학습\n",
      "✅ 하이브리드 추천 알고리즘 구현\n",
      "✅ 자유 문장 입력 파싱 시스템\n",
      "✅ 태그 기반 추천 시스템\n",
      "✅ 모델 저장/로드 기능\n",
      "✅ Flask API 연동 준비\n",
      "✅ 성능 분석 도구\n",
      "✅ 다양한 테스트 케이스\n",
      "✅ 에러 처리 및 디버깅\n",
      "✅ 완전한 문서화\n",
      "\n",
      "\n",
      "🎊 축하합니다! 강원도 관광지 추천 시스템이 완성되었습니다!\n",
      "이제 실제 사용자들에게 정확하고 유용한 관광지 추천을 제공할 수 있습니다.\n",
      "\n",
      "============================================================\n",
      "🎯 간단한 사용 예제\n",
      "============================================================\n",
      "\n",
      "📝 예제 1: 간단한 추천\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 24.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력: 봄에 산에서 힐링\n",
      "추천 결과:\n",
      "  1. 국립 삼봉자연휴양림 (점수: 0.661)\n",
      "  2. 강릉 솔향수목원 (점수: 0.644)\n",
      "  3. 태백 구와우마을(고원자생식물원) (점수: 0.631)\n",
      "\n",
      "📝 예제 2: 태그 조합 추천\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 23.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력: {'season': '여름', 'nature': ['바다'], 'target': ['가족']}\n",
      "추천 결과:\n",
      "  1. 작은후진해수욕장 (점수: 0.643)\n",
      "  2. 화진포해수욕장 (점수: 0.643)\n",
      "  3. 장호어촌체험마을 (점수: 0.637)\n",
      "\n",
      "============================================================\n",
      "🚀 시스템 준비 완료! 이제 마음껏 사용하세요!\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "### 최종 정리 및 사용법 안내\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"🎉 강원도 관광지 추천 시스템 구축 완료!\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n📁 생성된 파일 구조:\")\n",
    "print(\"\"\"\n",
    "project_root/\n",
    "├── data/\n",
    "│   ├── raw/gangwon_places_100.csv                 # 원본 데이터\n",
    "│   ├── processed/gangwon_places_100_processed.csv # 전처리된 데이터\n",
    "│   └── embeddings/place_embeddings_full768.npy    # 768차원 임베딩\n",
    "├── models/\n",
    "│   ├── xgboost/\n",
    "│   │   ├── season_model.joblib                    # 계절 분류 모델\n",
    "│   │   ├── nature_model.joblib                    # 자연환경 분류 모델\n",
    "│   │   ├── vibe_model.joblib                      # 분위기 분류 모델\n",
    "│   │   └── target_model.joblib                    # 대상 분류 모델\n",
    "│   └── encoders/\n",
    "│       ├── season_encoder.joblib                  # 계절 인코더\n",
    "│       ├── nature_encoder.joblib                  # 자연환경 인코더\n",
    "│       ├── vibe_encoder.joblib                    # 분위기 인코더\n",
    "│       └── target_encoder.joblib                  # 대상 인코더\n",
    "└── config/config.yaml                             # 설정 파일\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n🚀 사용법:\")\n",
    "print(\"\"\"\n",
    "1. 태그 기반 추천:\n",
    "   user_input = {\n",
    "       \"season\": \"여름\",\n",
    "       \"nature\": [\"바다\", \"자연\"],\n",
    "       \"vibe\": [\"감성\", \"휴식\"],\n",
    "       \"target\": [\"연인\"]\n",
    "   }\n",
    "   result = recommender.recommend_places(user_input, top_k=5)\n",
    "\n",
    "2. 자유 문장 기반 추천:\n",
    "   user_input = {\n",
    "       \"free_text\": \"겨울에 가족과 함께 스키를 타고 싶어요\"\n",
    "   }\n",
    "   result = recommender.recommend_places(user_input, top_k=5)\n",
    "\n",
    "3. Flask API 연동:\n",
    "   api_response = recommend_places_api(user_input, top_k=10)\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n⚙️ 주요 기능:\")\n",
    "print(\"\"\"\n",
    "✅ SBERT 기반 한국어 임베딩 생성 (768차원 유지)\n",
    "✅ XGBoost 다중 라벨 분류 (season, nature, vibe, target)\n",
    "✅ 하이브리드 점수 계산 (유사도 60% + 태그 40%)\n",
    "✅ 자유 문장 입력 파싱 및 태그 추출\n",
    "✅ 모델 및 인코더 저장/로드\n",
    "✅ Flask API 연동 준비\n",
    "✅ JSON 입출력 지원\n",
    "✅ 성능 분석 도구\n",
    "✅ 다양한 테스트 케이스 지원\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n📊 성능 지표:\")\n",
    "print(f\"- 데이터: {len(recommender.df)}개 관광지\")\n",
    "print(f\"- 임베딩 차원: {recommender.place_embeddings.shape[1]}차원\")\n",
    "print(f\"- 모델 타입: XGBoost (season: 단일라벨, nature/vibe/target: 다중라벨)\")\n",
    "print(f\"- 추천 방식: 하이브리드 (유사도 60% + 태그 40%)\")\n",
    "print(f\"- 지원 입력: 태그 기반 + 자유 문장 입력\")\n",
    "\n",
    "print(\"\\n🔄 모델 재사용:\")\n",
    "print(\"\"\"\n",
    "# 저장된 모델 로드\n",
    "new_recommender = GangwonPlaceRecommender()\n",
    "new_recommender.df = pd.read_csv('data/processed/gangwon_places_100_processed.csv')\n",
    "new_recommender.place_embeddings = np.load('data/embeddings/place_embeddings_full768.npy')\n",
    "new_recommender.preprocessor.load_encoders('models/encoders')\n",
    "new_recommender.xgb_trainer.load_models('models')\n",
    "\n",
    "# 추천 실행\n",
    "result = new_recommender.recommend_places(user_input, top_k=5)\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n💡 추가 활용 방안:\")\n",
    "print(\"\"\"\n",
    "1. 웹 애플리케이션 연동:\n",
    "   - Flask/Django 백엔드에 recommend_places_api() 함수 활용\n",
    "   - REST API 엔드포인트 구성\n",
    "   - 실시간 추천 서비스 제공\n",
    "\n",
    "2. 모바일 앱 연동:\n",
    "   - JSON 형태의 API 응답 활용\n",
    "   - 사용자 입력 파싱 기능 활용\n",
    "   - 오프라인 모델 배포 가능\n",
    "\n",
    "3. 성능 최적화:\n",
    "   - 임베딩 캐싱으로 응답 속도 향상\n",
    "   - 배치 추천 처리\n",
    "   - 모델 압축 및 경량화\n",
    "\n",
    "4. 기능 확장:\n",
    "   - 사용자 피드백 학습\n",
    "   - 협업 필터링 추가\n",
    "   - 개인화 추천 구현\n",
    "   - 실시간 학습 시스템\n",
    "   - 지역별 필터링 기능\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n📝 주의사항:\")\n",
    "print(\"\"\"\n",
    "- 첫 실행 시 SBERT 모델 다운로드로 시간이 소요될 수 있습니다\n",
    "- GPU 사용 시 더 빠른 임베딩 생성이 가능합니다\n",
    "- 실제 서비스 배포 시 보안 및 에러 처리를 강화하세요\n",
    "- 데이터 업데이트 시 모델 재학습이 필요할 수 있습니다\n",
    "- 추천 성능 향상을 위해 정기적인 모델 튜닝을 권장합니다\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n🌟 추천 시스템 특징:\")\n",
    "print(\"\"\"\n",
    "- 한국어 특화 SBERT 모델 사용 (snunlp/KR-SBERT-V40K-klueNLI-augSTS)\n",
    "- 하이브리드 추천 (의미적 유사도 + 태그 매칭)\n",
    "- 자유 문장 입력 지원으로 사용자 편의성 향상\n",
    "- 다중 라벨 분류로 정확한 태그 예측\n",
    "- 모델 저장/로드 기능으로 효율적인 운영\n",
    "- Flask API 연동으로 웹 서비스 확장 가능\n",
    "- 성능 분석 도구로 시스템 모니터링 가능\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n🎯 추천 시스템 성능:\")\n",
    "print(\"\"\"\n",
    "- 임베딩 기반 의미적 유사도 계산 (60% 가중치)\n",
    "- 태그 매칭 기반 정확도 향상 (40% 가중치)\n",
    "- 계절, 자연환경, 분위기, 대상별 세분화된 추천\n",
    "- 자유 문장 파싱으로 자연스러운 사용자 경험\n",
    "- 상위 K개 추천으로 다양한 선택지 제공\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"🚀 강원도 관광지 추천 시스템이 성공적으로 구축되었습니다!\")\n",
    "print(\"   이제 다양한 사용자 입력에 대해 정확한 관광지 추천이 가능합니다.\")\n",
    "print(\"   Flask API 연동을 통해 웹 서비스로 확장할 수 있습니다.\")\n",
    "print(\"   모든 오류가 수정되어 안정적으로 작동합니다.\")\n",
    "print(\"   태그 기반 추천과 자유 문장 입력을 모두 지원합니다.\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n📚 추가 학습 자료:\")\n",
    "print(\"\"\"\n",
    "- SBERT 모델 상세 정보: https://huggingface.co/snunlp/KR-SBERT-V40K-klueNLI-augSTS\n",
    "- XGBoost 공식 문서: https://xgboost.readthedocs.io/\n",
    "- Scikit-learn 다중 라벨 분류: https://scikit-learn.org/stable/modules/multiclass.html\n",
    "- Flask API 개발 가이드: https://flask.palletsprojects.com/\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n🔗 다음 단계:\")\n",
    "print(\"\"\"\n",
    "1. 웹 인터페이스 개발 (HTML/CSS/JavaScript)\n",
    "2. Flask/Django 백엔드 API 구축\n",
    "3. 데이터베이스 연동 (PostgreSQL/MySQL)\n",
    "4. 사용자 피드백 수집 시스템\n",
    "5. 추천 성능 모니터링 대시보드\n",
    "6. 모바일 앱 연동\n",
    "7. 실시간 추천 시스템 구축\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n✨ 완료된 기능들:\")\n",
    "print(\"\"\"\n",
    "✅ 데이터 전처리 및 정제\n",
    "✅ SBERT 임베딩 생성 (768차원)\n",
    "✅ XGBoost 다중 라벨 분류 모델 학습\n",
    "✅ 하이브리드 추천 알고리즘 구현\n",
    "✅ 자유 문장 입력 파싱 시스템\n",
    "✅ 태그 기반 추천 시스템\n",
    "✅ 모델 저장/로드 기능\n",
    "✅ Flask API 연동 준비\n",
    "✅ 성능 분석 도구\n",
    "✅ 다양한 테스트 케이스\n",
    "✅ 에러 처리 및 디버깅\n",
    "✅ 완전한 문서화\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n🎊 축하합니다! 강원도 관광지 추천 시스템이 완성되었습니다!\")\n",
    "print(\"이제 실제 사용자들에게 정확하고 유용한 관광지 추천을 제공할 수 있습니다.\")\n",
    "\n",
    "# ================================\n",
    "# 보너스: 간단한 사용 예제\n",
    "# ================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"🎯 간단한 사용 예제\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 예제 1: 간단한 추천\n",
    "print(\"\\n📝 예제 1: 간단한 추천\")\n",
    "simple_input = {\"free_text\": \"봄에 산에서 힐링\"}\n",
    "simple_result = recommender.recommend_places(simple_input, top_k=3)\n",
    "print(f\"입력: {simple_input['free_text']}\")\n",
    "print(\"추천 결과:\")\n",
    "for i, place in enumerate(simple_result['recommendations']):\n",
    "    print(f\"  {i+1}. {place['name']} (점수: {place['hybrid_score']:.3f})\")\n",
    "\n",
    "# 예제 2: 태그 조합 추천\n",
    "print(\"\\n📝 예제 2: 태그 조합 추천\")\n",
    "tag_input = {\"season\": \"여름\", \"nature\": [\"바다\"], \"target\": [\"가족\"]}\n",
    "tag_result = recommender.recommend_places(tag_input, top_k=3)\n",
    "print(f\"입력: {tag_input}\")\n",
    "print(\"추천 결과:\")\n",
    "for i, place in enumerate(tag_result['recommendations']):\n",
    "    print(f\"  {i+1}. {place['name']} (점수: {place['hybrid_score']:.3f})\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"🚀 시스템 준비 완료! 이제 마음껏 사용하세요!\")\n",
    "print(\"=\"*60) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ea4517-59d3-4c5f-be74-c3a011ebe00a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
